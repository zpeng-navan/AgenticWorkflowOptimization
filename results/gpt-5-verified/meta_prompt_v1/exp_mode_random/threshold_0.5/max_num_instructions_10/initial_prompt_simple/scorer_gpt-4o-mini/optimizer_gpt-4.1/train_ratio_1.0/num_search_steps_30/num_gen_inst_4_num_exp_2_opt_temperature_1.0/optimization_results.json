{
  "prompts_and_scores": [
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly states which legs to cancel (mentions departure, return, or specific cities/airports); otherwise, FULL.\n\nClassify only based on direct, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8825441383504952,
      "cancel_adj_b_acc": 0.8792792792792792,
      "partial_adj_b_acc": 0.8858333333333333,
      "word_count": 66,
      "step": 17
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True ONLY if the user specifically asks to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL ONLY if the user clearly requests cancelling specific legs (mentions departure, return, or names cities/airports for a leg); otherwise, FULL.\n\nONLY use explicit user statements. Never infer or assume intent.",
      "combined_score": 0.8753916600210944,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.865,
      "word_count": 68,
      "step": 12
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user directly and explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly specifies which legs to cancel (mentions departure, return, or specific cities/airports); otherwise, FULL.\n\nRely strictly on clear, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8687449770564902,
      "cancel_adj_b_acc": 0.8725225225225226,
      "partial_adj_b_acc": 0.865,
      "word_count": 67,
      "step": 22
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly specifies which legs to cancel (mentions departure, return, or specific cities/airports); otherwise, FULL.\n\nBase decisions solely on the user\u2019s direct statements\u2014never infer or assume intent.",
      "combined_score": 0.8677990862843238,
      "cancel_adj_b_acc": 0.8927927927927928,
      "partial_adj_b_acc": 0.8441666666666667,
      "word_count": 66,
      "step": 29
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True if, and only if, the user explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL if, and only if, the user clearly specifies which legs to cancel (mentions departure, return, or names cities/airports); otherwise, FULL.\n\nClassify solely on direct, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.867397898034329,
      "cancel_adj_b_acc": 0.8792792792792792,
      "partial_adj_b_acc": 0.8558333333333334,
      "word_count": 68,
      "step": 25
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a chat about cancellation, assign:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (by mentioning departure, return, or leg cities/airports); otherwise, FULL.\n\nAlways require clear, explicit statements\u2014never infer or guess user intent.",
      "combined_score": 0.8663068376179405,
      "cancel_adj_b_acc": 0.8896396396396398,
      "partial_adj_b_acc": 0.8441666666666667,
      "word_count": 69,
      "step": 7
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user unambiguously requests to cancel specific legs (mentions departure, return, or a specific leg\u2019s city/airport); otherwise, FULL.\n\nUse only explicit requests\u2014never infer or assume intent.",
      "combined_score": 0.8656252300470703,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.8341666666666665,
      "word_count": 66,
      "step": 13
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user specifically and explicitly asks to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests canceling specific legs (mentions departure, return, or cities/airports for a leg); otherwise, FULL.\n\nUse only direct and explicit user requests\u2014never infer or assume intent.",
      "combined_score": 0.8656252300470703,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.8341666666666665,
      "word_count": 68,
      "step": 25
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user unambiguously requests to cancel specific legs (mentions departure, return, or a specific leg\u2019s city/airport); otherwise, FULL.\n\nUse only explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8654341547188468,
      "cancel_adj_b_acc": 0.8761261261261262,
      "partial_adj_b_acc": 0.855,
      "word_count": 67,
      "step": 13
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user directly requests to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL only if the user clearly identifies specific legs to cancel (mentions departure, return, or cities/airports); else, FULL.\n\nUse only clear, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8650316167477686,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.845,
      "word_count": 63,
      "step": 18
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True ONLY if the user clearly, explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL ONLY if the user clearly specifies particular legs to cancel (referencing departure, return, or cities/airports); otherwise, FULL.\n\nONLY use explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8645947505673364,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8441666666666667,
      "word_count": 63,
      "step": 23
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly and explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user unmistakably specifies which legs to cancel (by explicitly mentioning departure, return, or leg cities/airports); otherwise, FULL.\n\nOnly consider direct, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8636723944616829,
      "cancel_adj_b_acc": 0.8725225225225226,
      "partial_adj_b_acc": 0.855,
      "word_count": 69,
      "step": 26
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user specifically and explicitly asks to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly identifies specific legs to cancel (by mentioning departure, return, or leg cities/airports); otherwise, FULL.\n\nOnly classify using direct and explicit user requests\u2014never infer or assume intent.",
      "combined_score": 0.861798897567857,
      "cancel_adj_b_acc": 0.8792792792792792,
      "partial_adj_b_acc": 0.845,
      "word_count": 69,
      "step": 20
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (by mentioning departure, return, or specific cities/airports); otherwise, FULL.\n\nOnly use direct, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8610105787614705,
      "cancel_adj_b_acc": 0.8896396396396398,
      "partial_adj_b_acc": 0.8341666666666665,
      "word_count": 67,
      "step": 15
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat, assign:\n\n1. cancel_not_for_all_passengers: True only if the user directly and explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly specifies which legs to cancel (by mentioning departure, return, or named cities/airports); otherwise, FULL.\n\nClassify solely on clear, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8604851694817507,
      "cancel_adj_b_acc": 0.871689497716895,
      "partial_adj_b_acc": 0.8495652173913042,
      "word_count": 68,
      "step": 19
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly specifies which legs to cancel (mentions departure, return, or city/airport names); otherwise, FULL.\n\nBase decisions strictly on the user\u2019s direct, explicit requests\u2014never infer or assume intent.",
      "combined_score": 0.8593193413374881,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8341666666666665,
      "word_count": 67,
      "step": 29
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly and explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly requests to cancel certain legs (such as mentioning departure, return, or names of cities/airports for a leg); otherwise, FULL.\n\nDecide strictly from clear, explicit user instructions\u2014never infer or assume intent.",
      "combined_score": 0.8593193413374881,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8341666666666665,
      "word_count": 75,
      "step": 13
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user directly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly identifies which legs to cancel (by mentioning departure, return, or cities/airports); otherwise, FULL.\n\nClassify solely based on clear, direct user statements\u2014never infer or guess intent.",
      "combined_score": 0.8589891150933585,
      "cancel_adj_b_acc": 0.8522522522522524,
      "partial_adj_b_acc": 0.8658333333333332,
      "word_count": 66,
      "step": 22
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly states which legs (by mentioning departure, return, or specific cities/airports) to cancel; otherwise, FULL.\n\nOnly use explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8571082514571555,
      "cancel_adj_b_acc": 0.8927927927927928,
      "partial_adj_b_acc": 0.8241666666666667,
      "word_count": 64,
      "step": 17
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user specifically and directly asks to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly identifies specific legs to cancel (by mentioning departure, return, or leg cities/airports); otherwise, FULL.\n\nOnly classify using explicit user statements\u2014never assume or infer intent.",
      "combined_score": 0.8570114821724165,
      "cancel_adj_b_acc": 0.8693693693693694,
      "partial_adj_b_acc": 0.845,
      "word_count": 67,
      "step": 20
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly specifies which flight legs to cancel (mentions departure, return, or specific cities/airports); otherwise, FULL.\n\nUse only the user\u2019s direct, explicit requests\u2014never infer or assume intent.",
      "combined_score": 0.8566573923390554,
      "cancel_adj_b_acc": 0.8927927927927928,
      "partial_adj_b_acc": 0.8233333333333333,
      "word_count": 66,
      "step": 29
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (mentions departure, return, or cities/airports of a leg); else, FULL.\n\nDecide both only from explicit user statements\u2014never guess or assume intent.",
      "combined_score": 0.8566573923390554,
      "cancel_adj_b_acc": 0.8927927927927928,
      "partial_adj_b_acc": 0.8233333333333333,
      "word_count": 69,
      "step": 9
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly and explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user unmistakably specifies which legs to cancel (by naming departure, return, or leg cities/airports); otherwise, FULL.\n\nUse only explicit user instructions\u2014never infer or guess intent.",
      "combined_score": 0.8561290972742527,
      "cancel_adj_b_acc": 0.8792792792792792,
      "partial_adj_b_acc": 0.8341666666666665,
      "word_count": 67,
      "step": 26
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user directly requests to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL only if the user clearly identifies specific legs to cancel (mentions departure, return, or cities/airports); else, FULL.\n\nUse only explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8544293800184284,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.825,
      "word_count": 62,
      "step": 18
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly identifies which legs to cancel (by mentioning departure, return, or specific leg cities/airports); otherwise, FULL.\n\nOnly classify using direct, explicit user requests\u2014never infer or assume intent.",
      "combined_score": 0.8539822387280015,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8241666666666667,
      "word_count": 68,
      "step": 20
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat, assign:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly specifies canceling certain legs (e.g., mentions departure, return, or particular cities/airports); otherwise, FULL.\n\nBase both labels strictly on explicit user instructions\u2014never infer or assume intent.",
      "combined_score": 0.8535346614665683,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8233333333333333,
      "word_count": 67,
      "step": 10
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user directly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly identifies which legs to cancel (by mentioning departure, return, or cities/airports); otherwise, FULL.\n\nStrictly classify based on clear, direct user statements\u2014never infer or guess intent.",
      "combined_score": 0.85237025783297,
      "cancel_adj_b_acc": 0.859009009009009,
      "partial_adj_b_acc": 0.8458333333333332,
      "word_count": 66,
      "step": 22
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. Set cancel_not_for_all_passengers to True only if the user explicitly says to cancel for specific passengers, otherwise False.\n2. Set partial_or_full to PARTIAL only if the user clearly requests to cancel specific legs (mentions departure, return, or leg cities/airports), otherwise FULL.\n\nUse only explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8498893995787911,
      "cancel_adj_b_acc": 0.8662162162162161,
      "partial_adj_b_acc": 0.8341666666666665,
      "word_count": 68,
      "step": 10
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a chat about cancellation, assign:\n\n1. cancel_not_for_all_passengers: True only if the user clearly states to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly requests to cancel specific legs (by mentioning departure, return, or leg cities/airports); otherwise, FULL.\n\nAlways require clear, explicit statements\u2014never infer or guess user intent.",
      "combined_score": 0.8489097398925642,
      "cancel_adj_b_acc": 0.8761261261261262,
      "partial_adj_b_acc": 0.8233333333333333,
      "word_count": 69,
      "step": 7
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: \n   - PARTIAL only if the user clearly states to cancel specific legs (such as departure, return, or names a leg\u2019s airport/city).\n   - Otherwise, FULL.\n\nBase both labels strictly on explicit statements in the chat\u2014never infer intent.",
      "combined_score": 0.8489097398925642,
      "cancel_adj_b_acc": 0.8761261261261262,
      "partial_adj_b_acc": 0.8233333333333333,
      "word_count": 75,
      "step": 5
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True if, and only if, the user explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL if, and only if, the user clearly specifies which legs to cancel (mentions \u201cdeparture\u201d, \u201creturn\u201d, or cites specific cities/airports); otherwise, FULL.\n\nOnly use the user\u2019s direct and explicit statements\u2014never infer or assume intent.",
      "combined_score": 0.8482579296290906,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.8025,
      "word_count": 70,
      "step": 25
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True ONLY if the user specifically asks to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL ONLY if the user clearly asks to cancel specific legs (mentions departure, return, or leg cities/airports); otherwise, FULL.\n\nBase both labels strictly on explicit user instructions\u2014never infer or assume intent.",
      "combined_score": 0.8481294951315628,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 68,
      "step": 12
    },
    {
      "prompt": "You are Ava, an assistant at the Navan flight kiosk. Given a flight booking with one or more legs and a chat history about flight cancellation, classify as follows:\n\n1. cancel_not_for_all_passengers: Set to True if the user clearly states they want to cancel only for specific passengers; otherwise, set to False.\n2. partial_or_full: \n   - Set to PARTIAL if the user specifies cancelling only the departure, return, or mentions airports related to specific legs.\n   - Set to FULL if the user requests cancellation without specifying legs or airports.\n\nOnly mark partial_or_full as PARTIAL if there is an explicit request about a part of the booking (e.g., particular leg, departure/return, or airport). Otherwise, default to FULL cancellation.",
      "combined_score": 0.8469067526938355,
      "cancel_adj_b_acc": 0.9396396396396396,
      "partial_adj_b_acc": 0.7708333333333335,
      "word_count": 115,
      "step": 0
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user directly and explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly specifies which legs to cancel (mentions departure, return, or specific cities/airports); otherwise, FULL.\n\nRely solely on clear, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8468343659425107,
      "cancel_adj_b_acc": 0.859009009009009,
      "partial_adj_b_acc": 0.835,
      "word_count": 67,
      "step": 22
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel certain legs (mentions departure, return, or leg cities/airports); otherwise, FULL.\n\nUse only clear, explicit user instructions\u2014never infer or guess intent.",
      "combined_score": 0.8466822462998371,
      "cancel_adj_b_acc": 0.8828828828828827,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 66,
      "step": 16
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True only if the user directly says to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (by stating departure/return, or naming a leg\u2019s city/airport); otherwise, FULL.\n\nBase both strictly on explicit user statements\u2014never guess or assume intent.",
      "combined_score": 0.8452418594146484,
      "cancel_adj_b_acc": 0.8927927927927928,
      "partial_adj_b_acc": 0.8025,
      "word_count": 69,
      "step": 9
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (mentions departure, return, or specific cities/airports); otherwise, FULL.\n\nBase your answers strictly on explicit user requests\u2014do not infer or assume intent.",
      "combined_score": 0.8450216450216451,
      "cancel_adj_b_acc": 0.8792792792792792,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 68,
      "step": 27
    },
    {
      "prompt": "You are Ava, an assistant at the Navan flight kiosk. Given a flight booking with one or more legs and a chat history about flight cancellation, classify as follows:\n\n1. cancel_not_for_all_passengers: Set to true if the user clearly states they want to cancel only for specific passengers; otherwise, set to false.\n2. partial_or_full: \n   - Set to PARTIAL if the user specifies cancelling only the departure, return, or mentions airports related to specific legs.\n   - Set to FULL if the user requests cancellation without specifying any particular leg or segment.\n\nUse context from the conversation and booking details. Focus on whether the request is for part or all of the booking, and for all or some passengers.",
      "combined_score": 0.8440192913228906,
      "cancel_adj_b_acc": 0.9027027027027028,
      "partial_adj_b_acc": 0.7925,
      "word_count": 116,
      "step": 0
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly and directly requests cancellation for specific passengers; else, False.\n2. partial_or_full: PARTIAL only if the user specifically mentions which legs to cancel (such as departure, return, or cities/airports); else, FULL.\n\nOnly use explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8440165697726101,
      "cancel_adj_b_acc": 0.8657657657657658,
      "partial_adj_b_acc": 0.8233333333333333,
      "word_count": 64,
      "step": 24
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel certain legs (mentions departure, return, or leg cities/airports); otherwise, FULL.\n\nOnly consider direct, explicit user statements\u2014never infer or guess intent.",
      "combined_score": 0.8426384655316997,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.7925,
      "word_count": 66,
      "step": 16
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (one or more legs) and a cancellation chat, assign two labels:\n\n1. cancel_not_for_all_passengers: True only if the user clearly states to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel certain legs (mentions departure, return, or specific cities/airports); otherwise, FULL.\n\nUse only explicit user instructions\u2014never infer or assume intent.",
      "combined_score": 0.8422016513051714,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8025,
      "word_count": 67,
      "step": 12
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (with one or more legs) and a chat about cancellation, output:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly requests to cancel certain legs (by mentioning departure, return, or leg airports/cities); otherwise, FULL.\n\nOnly use clear, explicit user instructions\u2014never infer or guess intent.",
      "combined_score": 0.8422016513051714,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.8025,
      "word_count": 70,
      "step": 8
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (by mentioning departure, return, or cities/airports for a leg); otherwise, FULL.\n\nRely only on explicit user statements. Never infer or guess intent.",
      "combined_score": 0.8420985147985898,
      "cancel_adj_b_acc": 0.8729729729729732,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 70,
      "step": 15
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (mentions departure, return, or names cities/airports); otherwise, FULL.\n\nBase your answers strictly on explicit user requests\u2014do not infer or assume intent.",
      "combined_score": 0.8418888829512461,
      "cancel_adj_b_acc": 0.8725225225225226,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 68,
      "step": 27
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly and directly requests cancellation for specific passengers; else, False.\n2. partial_or_full: PARTIAL only if the user specifically mentions which legs to cancel (such as departure, return, or cities/airports); else, FULL.\n\nOnly use explicit user instructions\u2014never infer or assume intent.",
      "combined_score": 0.8410271483539974,
      "cancel_adj_b_acc": 0.8824324324324324,
      "partial_adj_b_acc": 0.8033333333333332,
      "word_count": 64,
      "step": 21
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True only if the user directly says to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel specific legs (by stating departure/return, or naming a leg\u2019s city/airport); else, FULL.\n\nBase both only on explicit user statements\u2014never guess or assume intent.",
      "combined_score": 0.8404183174501196,
      "cancel_adj_b_acc": 0.8693693693693694,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 69,
      "step": 9
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly requests to cancel specific legs (e.g., mentions departure, return, or names cities/airports matching a leg); otherwise, FULL.\n\nDecide both labels only from clear, explicit user statements\u2014never infer intent.",
      "combined_score": 0.8393420894083625,
      "cancel_adj_b_acc": 0.8797297297297297,
      "partial_adj_b_acc": 0.8025,
      "word_count": 73,
      "step": 6
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (with one or more legs) and a chat about cancellation, assign:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly requests to cancel certain legs (by mentioning departure, return, or leg airports/cities); otherwise, FULL.\n\nOnly use clear, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8366618809290592,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.7925,
      "word_count": 70,
      "step": 8
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a chat about cancellation, assign:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly states cancel for specific passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL only if the user clearly specifies to cancel certain legs (e.g., mentions departure, return, or airport/city of a leg).\n   - Otherwise, FULL.\n\nUse only explicit statements from the chat; never infer or assume intent.",
      "combined_score": 0.836475274406309,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.7816666666666667,
      "word_count": 74,
      "step": 7
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (with one or more legs) and a chat about cancellation, classify as follows:\n\n1. cancel_not_for_all_passengers: Set to True only if the user clearly states they want to cancel for specific passengers; otherwise, set to False.\n\n2. partial_or_full:\n   - Set to PARTIAL if the user asks to cancel only certain legs (e.g., specifies departure, return, or names specific airports/cities matching flight legs).\n   - Otherwise, set to FULL.\n\nMatch only clear, explicit user requests. If not clearly specified, default to FULL and all passengers.",
      "combined_score": 0.836475274406309,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.7816666666666667,
      "word_count": 93,
      "step": 1
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. Set cancel_not_for_all_passengers to True only if the user explicitly says to cancel for specific passengers; otherwise, set to False.\n2. Set partial_or_full to PARTIAL only if the user clearly requests to cancel specific legs (mentions departure, return, or particular cities/airports of a leg); otherwise, set to FULL.\n\nDecide both strictly from explicit user statements\u2014never assume or infer intent.",
      "combined_score": 0.836236020607823,
      "cancel_adj_b_acc": 0.8495495495495495,
      "partial_adj_b_acc": 0.8233333333333333,
      "word_count": 77,
      "step": 10
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly and directly requests cancellation for specific passengers; else, False.\n2. partial_or_full: PARTIAL only if the user specifically mentions which legs to cancel (such as departure, return, or cities/airports); else, FULL.\n\nOnly use explicit user instructions\u2014never infer, guess, or assume intent.",
      "combined_score": 0.8355474151089085,
      "cancel_adj_b_acc": 0.859009009009009,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 65,
      "step": 24
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (with one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL if the user specifically asks to cancel only certain legs (such as departure, return, or names cities/airports matching a leg).\n   - FULL if the user\u2019s request is to cancel without specifying legs or segments.\n\nBase both labels strictly on clear, explicit user statements in the chat.",
      "combined_score": 0.8351094766417023,
      "cancel_adj_b_acc": 0.8963963963963963,
      "partial_adj_b_acc": 0.7816666666666667,
      "word_count": 88,
      "step": 2
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True ONLY if the user directly and explicitly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL ONLY if the user clearly specifies which legs to cancel (by mentioning departure, return, or named cities/airports); otherwise, FULL.\n\nClassify strictly based on the user\u2019s explicit statements. Never infer or guess intent.",
      "combined_score": 0.8348935015601683,
      "cancel_adj_b_acc": 0.861904761904762,
      "partial_adj_b_acc": 0.8095238095238095,
      "word_count": 71,
      "step": 19
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user specifically and explicitly asks to cancel for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests canceling specific legs (mentions departure, return, or leg cities/airports); otherwise, FULL.\n\nBase your answer strictly on explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8340529648819804,
      "cancel_adj_b_acc": 0.8558558558558558,
      "partial_adj_b_acc": 0.8133333333333335,
      "word_count": 67,
      "step": 25
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True ONLY if the user directly and clearly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL ONLY if the user explicitly requests to cancel certain legs (by mentioning departure, return, or named cities/airports); otherwise, FULL.\n\nClassify strictly based on the user\u2019s explicit statements\u2014never infer or guess intent.",
      "combined_score": 0.8335887667257194,
      "cancel_adj_b_acc": 0.8773892773892773,
      "partial_adj_b_acc": 0.7939534883720931,
      "word_count": 70,
      "step": 19
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: \n   - PARTIAL only if the user clearly states to cancel specific legs (e.g., mentions departure, return, or leg cities/airports).\n   - Otherwise, FULL.\n\nBase both labels strictly on explicit statements in the chat\u2014never infer intent.",
      "combined_score": 0.833542266340265,
      "cancel_adj_b_acc": 0.8927927927927928,
      "partial_adj_b_acc": 0.7816666666666667,
      "word_count": 73,
      "step": 5
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. For each booking (with one or more legs) and cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True only if the user clearly asks to cancel for specific passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL if the user explicitly requests to cancel specific legs (e.g., mentions departure, return, or names an airport/city matching a leg).\n   - FULL if cancellation is for the whole booking or legs aren\u2019t specified.\n\nUse only explicit user statements; do not infer intent.",
      "combined_score": 0.833542266340265,
      "cancel_adj_b_acc": 0.8927927927927928,
      "partial_adj_b_acc": 0.7816666666666667,
      "word_count": 81,
      "step": 4
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly requests to cancel certain legs (mentions departure, return, or leg cities/airports); otherwise, FULL.\n\nOnly consider direct, explicit user instructions\u2014never infer or guess intent.",
      "combined_score": 0.8322175280413568,
      "cancel_adj_b_acc": 0.8761261261261262,
      "partial_adj_b_acc": 0.7925,
      "word_count": 66,
      "step": 16
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full: \n   - PARTIAL only if the user explicitly requests to cancel specific legs (like departure, return, or names cities/airports matching a leg).\n   - Otherwise, FULL.\n\nBase both on explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8316804370461521,
      "cancel_adj_b_acc": 0.8630630630630631,
      "partial_adj_b_acc": 0.8025,
      "word_count": 73,
      "step": 6
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (with one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for certain passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL if the user specifically asks to cancel only certain legs (such as departure, return, or names cities/airports matching a leg).\n   - FULL if the user\u2019s request is general or does not mention specific legs.\n\nBase both labels strictly on clear, explicit user statements in the chat.",
      "combined_score": 0.8316804370461521,
      "cancel_adj_b_acc": 0.8630630630630631,
      "partial_adj_b_acc": 0.8025,
      "word_count": 88,
      "step": 2
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (with one or more legs) and a chat about cancellation, classify as follows:\n\n1. cancel_not_for_all_passengers: Set to True only if the user clearly states they want to cancel for specific passengers; otherwise, set to False.\n\n2. partial_or_full:\n   - Set to PARTIAL if the user asks to cancel only certain legs (e.g., specifies departure, return, or names specific airports/cities matching a leg).\n   - Otherwise, set to FULL.\n\nMatch only clear, explicit user requests. If not clearly specified, default to FULL and all passengers.",
      "combined_score": 0.8307152547550379,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.7716666666666665,
      "word_count": 93,
      "step": 1
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True ONLY if the user clearly, explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL ONLY if the user clearly specifies particular legs to cancel (referencing departure, return, or cities/airports); otherwise, FULL.\n\nUse only explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8305854919014307,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.7816666666666667,
      "word_count": 63,
      "step": 23
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True ONLY if the user clearly states to cancel for specific passengers; else, False.\n2. partial_or_full: PARTIAL ONLY if the user specifies certain legs to cancel (by mentioning departure, return, or leg cities/airports); else, FULL.\n\nUse only direct, explicit user statements\u2014never infer or guess intent.",
      "combined_score": 0.8305854919014307,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.7816666666666667,
      "word_count": 65,
      "step": 23
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user directly requests to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL only if the user clearly identifies specific legs to cancel (mentions departure, return, or cities/airports); else, FULL.\n\nUse only explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8300681911518482,
      "cancel_adj_b_acc": 0.8693693693693694,
      "partial_adj_b_acc": 0.7941666666666665,
      "word_count": 62,
      "step": 18
    },
    {
      "prompt": "You are Ava, an assistant at the Navan flight kiosk. Given a flight booking with one or more legs and a chat history, classify the user\u2019s cancellation intent:\n\n1. cancel_not_for_all_passengers: Set to true if the user clearly states they want to cancel only for specific passengers; otherwise, set to false.\n2. partial_or_full: \n   - Set to PARTIAL if the user specifies cancelling only certain legs (e.g., mentions departure, return, or specific airports/routes).\n   - Set to FULL if the user does not specify and wants to cancel the entire booking.\n\nBase your decision only on explicit user statements in the chat.",
      "combined_score": 0.8257953162188186,
      "cancel_adj_b_acc": 0.8495495495495495,
      "partial_adj_b_acc": 0.8033333333333332,
      "word_count": 99,
      "step": 0
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. With a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly specifies which legs to cancel (mentions departure, return, or leg cities/airports); otherwise, FULL.\n\nBase decisions solely on direct, explicit user statements\u2014never infer or assume.",
      "combined_score": 0.8249060261043631,
      "cancel_adj_b_acc": 0.8860360360360362,
      "partial_adj_b_acc": 0.7716666666666665,
      "word_count": 64,
      "step": 28
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. With a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly requests cancellation for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly specifies which legs to cancel (mentions departure, return, or leg cities/airports); otherwise, FULL.\n\nBase decisions solely on direct, explicit user statements\u2014never infer or assume intent.",
      "combined_score": 0.8243969380050008,
      "cancel_adj_b_acc": 0.8995495495495496,
      "partial_adj_b_acc": 0.7608333333333333,
      "word_count": 65,
      "step": 28
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (with one or more legs) and a chat about cancellation, output:\n\n1. cancel_not_for_all_passengers: True only if the user clearly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user explicitly requests to cancel certain legs (by specifying departure, return, or leg airports/cities); otherwise, FULL.\n\nOnly use clear, explicit user instructions\u2014never infer or guess intent.",
      "combined_score": 0.821965749001846,
      "cancel_adj_b_acc": 0.8792792792792792,
      "partial_adj_b_acc": 0.7716666666666665,
      "word_count": 70,
      "step": 8
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a flight booking (one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly says to cancel for specific passengers; otherwise, False.\n2. partial_or_full: \n   - PARTIAL only if the user clearly requests to cancel specific legs (e.g., mentions departure, return, or leg cities/airports).\n   - Otherwise, FULL.\n\nBase both labels strictly on explicit statements in the chat\u2014never infer intent.",
      "combined_score": 0.8205853676316484,
      "cancel_adj_b_acc": 0.8761261261261262,
      "partial_adj_b_acc": 0.7716666666666665,
      "word_count": 73,
      "step": 5
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. For each booking (with one or more legs) and cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True only if the user clearly states cancel for specific passengers; otherwise, False.\n2. partial_or_full: \n   - PARTIAL only if the user explicitly requests cancellation of specific legs (e.g., says departure, return, or names cities/airports matching a leg).\n   - Otherwise, FULL.\n\nRely only on clear, explicit user statements for both labels\u2014do not infer intent.",
      "combined_score": 0.815779331053771,
      "cancel_adj_b_acc": 0.8792792792792792,
      "partial_adj_b_acc": 0.7608333333333333,
      "word_count": 74,
      "step": 4
    },
    {
      "prompt": "You are Ava, Navan\u2019s flight assistant. Given a booking (one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True ONLY if the user clearly requests cancellation for specific passengers; else, False.\n2. partial_or_full: PARTIAL ONLY if the user explicitly specifies certain legs to cancel (by mentioning departure, return, or leg cities/airports); else, FULL.\n\nUse only direct, explicit user statements\u2014never infer or guess intent.",
      "combined_score": 0.8128592637534875,
      "cancel_adj_b_acc": 0.8725225225225226,
      "partial_adj_b_acc": 0.7608333333333333,
      "word_count": 65,
      "step": 23
    },
    {
      "prompt": "You are Ava, Navan's flight assistant. Given a booking (one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True only if the user clearly and directly requests cancellation for specific passengers; else, False.\n2. partial_or_full: PARTIAL only if the user specifically mentions which legs to cancel (such as departure, return, or cities/airports); else, FULL.\n\nOnly use explicit user instructions\u2014never infer or guess intent.",
      "combined_score": 0.8085316106756513,
      "cancel_adj_b_acc": 0.8252252252252252,
      "partial_adj_b_acc": 0.7925,
      "word_count": 64,
      "step": 21
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. For each flight cancellation chat and booking, classify:\n\n1. cancel_not_for_all_passengers: True if the user explicitly asks to cancel for only specific passengers; otherwise, False.\n2. partial_or_full: \n   - PARTIAL if the user clearly states to cancel only certain legs (e.g., specifies departure/return or names an airport or leg).\n   - FULL if cancellation is requested for the whole booking or legs aren\u2019t specified.\n\nBase both labels strictly on explicit user instructions in the chat.",
      "combined_score": 0.8015325141515948,
      "cancel_adj_b_acc": 0.922972972972973,
      "partial_adj_b_acc": 0.7083333333333335,
      "word_count": 79,
      "step": 3
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. For a booking (with one or more legs) and a cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True only if the user explicitly requests cancellation for certain passengers; otherwise, False.\n2. partial_or_full: PARTIAL only if the user clearly states canceling specific legs (mentions departure, return, or a leg\u2019s city/airport); otherwise, FULL.\n\nRely solely on clear, explicit user instructions\u2014never infer or guess intent.",
      "combined_score": 0.8010053619302949,
      "cancel_adj_b_acc": 0.8729729729729732,
      "partial_adj_b_acc": 0.74,
      "word_count": 67,
      "step": 11
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. For each booking (with one or more legs) and cancellation chat, classify:\n\n1. cancel_not_for_all_passengers: True only if the user clearly states cancel for specific passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL if the user explicitly requests to cancel certain legs (e.g., departure, return, or names specific cities/airports).\n   - FULL if the user requests cancellation without specifying legs.\n\nOnly mark as True or PARTIAL if the user's words clearly indicate it; otherwise, default to False and FULL.",
      "combined_score": 0.7994849977608598,
      "cancel_adj_b_acc": 0.8693693693693694,
      "partial_adj_b_acc": 0.74,
      "word_count": 83,
      "step": 4
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True ONLY if the user explicitly asks to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL ONLY if the user clearly requests to cancel specific legs (mentions a leg, direction, or cites a city/airport); else, FULL.\n\nDecide solely based on clear user statements\u2014never infer or assume intent.",
      "combined_score": 0.7991956655309165,
      "cancel_adj_b_acc": 0.8828828828828827,
      "partial_adj_b_acc": 0.73,
      "word_count": 69,
      "step": 14
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a cancellation chat:\n\n1. cancel_not_for_all_passengers: True ONLY if the user explicitly asks to cancel for certain passengers; else, False.\n2. partial_or_full: PARTIAL ONLY if the user clearly requests to cancel specific legs (mentions a leg, direction, or cites a city/airport); else, FULL.\n\nDecide solely based on clear user statements. Never infer or assume intent.",
      "combined_score": 0.7964157505048239,
      "cancel_adj_b_acc": 0.8761261261261262,
      "partial_adj_b_acc": 0.73,
      "word_count": 70,
      "step": 14
    },
    {
      "prompt": "You are Ava, an assistant helping users cancel flights. Your task is to classify flight cancellation requests with two labels:\n\n1. cancel_not_for_all_passengers: Is the cancellation for fewer than all passengers? Set to true if the user specifically wants to cancel for only some passengers; otherwise, set to false.\n\n2. partial_or_full: Is the cancellation for the whole booking (FULL) or just specific flights/legs (PARTIAL)? Set to PARTIAL if the user asks to cancel only the departure/return leg, mentions specific cities/airports/legs, or refers to select parts of the trip. Otherwise, set to FULL.\n\nAlways look for explicit or clear user intent about which passengers and which flight segments should be canceled.",
      "combined_score": 0.7782345305062743,
      "cancel_adj_b_acc": 0.7364864864864864,
      "partial_adj_b_acc": 0.825,
      "word_count": 109,
      "step": 0
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. For each flight cancellation chat and booking, apply these labels:\n\n1. cancel_not_for_all_passengers: True if the user clearly says to cancel for only certain passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL if the user explicitly asks to cancel only certain legs (e.g., departure/return, or names specific airports/cities matching a leg).\n   - FULL if the request does not specify flight legs.\n\nBase both labels strictly on clear user instructions in the chat; do not infer intent.",
      "combined_score": 0.761192146274176,
      "cancel_adj_b_acc": 0.8364864864864865,
      "partial_adj_b_acc": 0.6983333333333333,
      "word_count": 81,
      "step": 3
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True if the user clearly asks to cancel only for some passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL if the user specifies canceling only certain legs (e.g., departure, return, or by airport/city).\n   - FULL if the user requests cancellation without specifying a leg or segment.\n\nRely only on explicit user intent in the chat for both labels.",
      "combined_score": 0.7461696007710494,
      "cancel_adj_b_acc": 0.713063063063063,
      "partial_adj_b_acc": 0.7825,
      "word_count": 80,
      "step": 1
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. For each flight cancellation chat and booking, apply these labels:\n\n1. cancel_not_for_all_passengers: True if the user clearly says to cancel for only certain passengers; otherwise, False.\n2. partial_or_full:\n   - PARTIAL if the user explicitly asks to cancel only certain legs (e.g., departure/return, named cities, or flight segments).\n   - Otherwise, FULL.\n\nOnly use explicit statements in the chat. If not clearly specified, default to FULL and all passengers.",
      "combined_score": 0.737653628499489,
      "cancel_adj_b_acc": 0.8599099099099099,
      "partial_adj_b_acc": 0.6458333333333335,
      "word_count": 74,
      "step": 3
    },
    {
      "prompt": "You are Ava, the Navan flight assistant. Given a booking (with one or more legs) and a chat about cancellation, classify:\n\n1. cancel_not_for_all_passengers: True if the user clearly asks to cancel only for some passengers; otherwise, False.\n2. partial_or_full: \n   - PARTIAL if the user specifically asks to cancel only certain legs (e.g., mentions departure, return, or specific cities/airports).\n   - FULL if the user requests to cancel without specifying particular legs.\n\nRely only on explicit user requests\u2014do not infer intent.",
      "combined_score": 0.6728594480937556,
      "cancel_adj_b_acc": 0.5792792792792794,
      "partial_adj_b_acc": 0.8025,
      "word_count": 79,
      "step": 1
    },
    {
      "prompt": "Your name is Ava. You work for Navan, a company that builds a Corporate travel & expense management system. You are an assistant at the flight kiosk, where user wants to cancel their flight. Flight booking consists of legs. For example, if user has a one way flight, then there will be only one leg. If user books a round trip flight from New York to San Francisco, in that case such flight booking has 2 legs, first leg from New York to San Francisco, and second leg from San Francisco back to New York.\n\n### Your task ###\nYou have a task to identify if user wants to cancel only part of their flight booking and if user wants to cancel the booking for fewer than all passengers in the reservation.\n\nUser wants to make a partial cancellation in the following cases:\n- if they explicitly mention that they want to cancel their departure  flight or return flight\n- if they mention specific airports that match legs in their flight booking\n\nIf user request does not mention anything about specific part of their flight booking, it means they want to cancel the entire booking so partial_or_full should be FULL. Otherwise, partial_or_full should be PARTIAL.\n\nWhen analyzing chat history, check if the user explicitly mentions wanting to cancel the booking for fewer than all passengers in the reservation. Set the flag cancel_not_for_all_passengers to true if the cancellation is not for all passengers. Set the flag cancel_not_for_all_passengers to false if the cancellation applies to the entire passengers in booking.",
      "combined_score": 0.642287882008601,
      "cancel_adj_b_acc": 0.50990990990991,
      "partial_adj_b_acc": 0.8675000000000002,
      "word_count": 258,
      "step": -1
    }
  ],
  "step_statistics": [
    {
      "step": 0,
      "num_instructions": 4,
      "md5_hashes": [
        "341c91463c250bece3f1765e99216cb1",
        "9d5fa6f5d913486a2a289d0f39c7f38a",
        "57df48531a8b462cbf7d02f659538975",
        "263994aa37f8794b6434ba473e800405"
      ],
      "combined_scores_mean": 0.8237389726854547,
      "combined_scores_std": 0.027490544562259196,
      "combined_scores_values": [
        0.7782345305062743,
        0.8469067526938355,
        0.8257953162188186,
        0.8440192913228906
      ],
      "word_counts_mean": 109.75,
      "word_counts_std": 6.7592529172978875,
      "word_counts_values": [
        109,
        115,
        99,
        116
      ],
      "cancel_precision_mean": 0.9243371957316641,
      "cancel_precision_std": 0.024840414903554056,
      "cancel_precision_values": [
        0.9574468085106383,
        0.9354838709677419,
        0.9137931034482759,
        0.890625
      ],
      "cancel_recall_mean": 0.8875,
      "cancel_recall_std": 0.085289539543578,
      "cancel_recall_values": [
        0.75,
        0.9666666666666667,
        0.8833333333333333,
        0.95
      ],
      "cancel_f1_mean": 0.9024002727284227,
      "cancel_f1_std": 0.04001173162507198,
      "cancel_f1_values": [
        0.8411214953271028,
        0.9508196721311475,
        0.8983050847457628,
        0.9193548387096774
      ],
      "cancel_accuracy_mean": 0.9459134615384615,
      "cancel_accuracy_std": 0.019042042689609216,
      "cancel_accuracy_values": [
        0.9182692307692307,
        0.9711538461538461,
        0.9423076923076923,
        0.9519230769230769
      ],
      "cancel_balanced_accuracy_mean": 0.9285472972972972,
      "cancel_balanced_accuracy_std": 0.03832185035397419,
      "cancel_balanced_accuracy_values": [
        0.8682432432432432,
        0.9698198198198198,
        0.9247747747747748,
        0.9513513513513514
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8570945945945946,
      "cancel_adj_balanced_accuracy_std": 0.07664370070794838,
      "cancel_adj_balanced_accuracy_values": [
        0.7364864864864864,
        0.9396396396396396,
        0.8495495495495495,
        0.9027027027027028
      ],
      "partial_precision_mean": 0.9437672729028131,
      "partial_precision_std": 0.038457417064698816,
      "partial_precision_values": [
        0.8936170212765957,
        1.0,
        0.9302325581395349,
        0.9512195121951219
      ],
      "partial_recall_mean": 0.8229166666666667,
      "partial_recall_std": 0.037557825786083215,
      "partial_recall_values": [
        0.875,
        0.7708333333333334,
        0.8333333333333334,
        0.8125
      ],
      "partial_f1_mean": 0.8775810337782022,
      "partial_f1_std": 0.004914386293706129,
      "partial_f1_values": [
        0.8842105263157894,
        0.8705882352941177,
        0.8791208791208791,
        0.8764044943820225
      ],
      "partial_accuracy_mean": 0.9256756756756757,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.9256756756756757,
        0.9256756756756757,
        0.9256756756756757,
        0.9256756756756757
      ],
      "partial_balanced_accuracy_mean": 0.8989583333333333,
      "partial_balanced_accuracy_std": 0.009765034704381602,
      "partial_balanced_accuracy_values": [
        0.9125,
        0.8854166666666667,
        0.9016666666666666,
        0.89625
      ],
      "partial_adj_balanced_accuracy_mean": 0.7979166666666667,
      "partial_adj_balanced_accuracy_std": 0.0195300694087632,
      "partial_adj_balanced_accuracy_values": [
        0.825,
        0.7708333333333335,
        0.8033333333333332,
        0.7925
      ]
    },
    {
      "step": 1,
      "num_instructions": 4,
      "md5_hashes": [
        "0d4bcf7dcca79ef8a604e2dc805127f2",
        "6086e73f26b1d8b67dbf6c7fc4880106",
        "4d0ef8d069e083d022d01e9faa14d943",
        "acc406a1a6fd8ce531dfb9d4b8846ce7"
      ],
      "combined_scores_mean": 0.771554894506538,
      "combined_scores_std": 0.06726776388382162,
      "combined_scores_values": [
        0.7461696007710494,
        0.836475274406309,
        0.8307152547550379,
        0.6728594480937556
      ],
      "word_counts_mean": 86.25,
      "word_counts_std": 6.7592529172978875,
      "word_counts_values": [
        80,
        93,
        93,
        79
      ],
      "cancel_precision_mean": 0.8995806857645472,
      "cancel_precision_std": 0.04307285048536692,
      "cancel_precision_values": [
        0.9361702127659575,
        0.9180327868852459,
        0.9180327868852459,
        0.8260869565217391
      ],
      "cancel_recall_mean": 0.8083333333333332,
      "cancel_recall_std": 0.1299038105676658,
      "cancel_recall_values": [
        0.7333333333333333,
        0.9333333333333333,
        0.9333333333333333,
        0.6333333333333333
      ],
      "cancel_f1_mean": 0.8476626770097538,
      "cancel_f1_std": 0.0864132451732956,
      "cancel_f1_values": [
        0.822429906542056,
        0.9256198347107438,
        0.9256198347107438,
        0.7169811320754716
      ],
      "cancel_accuracy_mean": 0.9194711538461539,
      "cancel_accuracy_std": 0.041687849028905384,
      "cancel_accuracy_values": [
        0.9086538461538461,
        0.9567307692307693,
        0.9567307692307693,
        0.8557692307692307
      ],
      "cancel_balanced_accuracy_mean": 0.8864301801801802,
      "cancel_balanced_accuracy_std": 0.06761548132242431,
      "cancel_balanced_accuracy_values": [
        0.8565315315315315,
        0.9497747747747748,
        0.9497747747747748,
        0.7896396396396397
      ],
      "cancel_adj_balanced_accuracy_mean": 0.7728603603603603,
      "cancel_adj_balanced_accuracy_std": 0.13523096264484863,
      "cancel_adj_balanced_accuracy_values": [
        0.713063063063063,
        0.8995495495495496,
        0.8995495495495496,
        0.5792792792792794
      ],
      "partial_precision_mean": 0.9569826007326007,
      "partial_precision_std": 0.019251730138658253,
      "partial_precision_values": [
        0.9285714285714286,
        0.9743589743589743,
        0.95,
        0.975
      ],
      "partial_recall_mean": 0.8020833333333333,
      "partial_recall_std": 0.010416666666666685,
      "partial_recall_values": [
        0.8125,
        0.7916666666666666,
        0.7916666666666666,
        0.8125
      ],
      "partial_f1_mean": 0.8725574712643678,
      "partial_f1_std": 0.008745133820435904,
      "partial_f1_values": [
        0.8666666666666667,
        0.8735632183908046,
        0.8636363636363636,
        0.8863636363636364
      ],
      "partial_accuracy_mean": 0.9239864864864865,
      "partial_accuracy_std": 0.005602406740465187,
      "partial_accuracy_values": [
        0.918918918918919,
        0.9256756756756757,
        0.918918918918919,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.8922916666666667,
      "partial_balanced_accuracy_std": 0.005594050659207334,
      "partial_balanced_accuracy_values": [
        0.89125,
        0.8908333333333334,
        0.8858333333333333,
        0.90125
      ],
      "partial_adj_balanced_accuracy_mean": 0.7845833333333334,
      "partial_adj_balanced_accuracy_std": 0.011188101318414669,
      "partial_adj_balanced_accuracy_values": [
        0.7825,
        0.7816666666666667,
        0.7716666666666665,
        0.8025
      ]
    },
    {
      "step": 2,
      "num_instructions": 2,
      "md5_hashes": [
        "abbc60e73cc93edcfeba94bfacf6ebc6",
        "bcddc6594a56ad1430cda86b084b5af2"
      ],
      "combined_scores_mean": 0.8333949568439272,
      "combined_scores_std": 0.0017145197977750937,
      "combined_scores_values": [
        0.8316804370461521,
        0.8351094766417023
      ],
      "word_counts_mean": 88.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        88,
        88
      ],
      "cancel_precision_mean": 0.9473522167487685,
      "cancel_precision_std": 0.000923645320197064,
      "cancel_precision_values": [
        0.9464285714285714,
        0.9482758620689655
      ],
      "cancel_recall_mean": 0.8999999999999999,
      "cancel_recall_std": 0.016666666666666663,
      "cancel_recall_values": [
        0.8833333333333333,
        0.9166666666666666
      ],
      "cancel_f1_mean": 0.9229982466393922,
      "cancel_f1_std": 0.00920514319111626,
      "cancel_f1_values": [
        0.9137931034482759,
        0.9322033898305084
      ],
      "cancel_accuracy_mean": 0.9567307692307692,
      "cancel_accuracy_std": 0.004807692307692346,
      "cancel_accuracy_values": [
        0.9519230769230769,
        0.9615384615384616
      ],
      "cancel_balanced_accuracy_mean": 0.9398648648648649,
      "cancel_balanced_accuracy_std": 0.008333333333333304,
      "cancel_balanced_accuracy_values": [
        0.9315315315315316,
        0.9481981981981982
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8797297297297297,
      "cancel_adj_balanced_accuracy_std": 0.016666666666666607,
      "cancel_adj_balanced_accuracy_values": [
        0.8630630630630631,
        0.8963963963963963
      ],
      "partial_precision_mean": 0.9746794871794872,
      "partial_precision_std": 0.0003205128205128194,
      "partial_precision_values": [
        0.975,
        0.9743589743589743
      ],
      "partial_recall_mean": 0.8020833333333333,
      "partial_recall_std": 0.010416666666666685,
      "partial_recall_values": [
        0.8125,
        0.7916666666666666
      ],
      "partial_f1_mean": 0.8799634273772206,
      "partial_f1_std": 0.006400208986415856,
      "partial_f1_values": [
        0.8863636363636364,
        0.8735632183908046
      ],
      "partial_accuracy_mean": 0.9290540540540541,
      "partial_accuracy_std": 0.0033783783783783994,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9256756756756757
      ],
      "partial_balanced_accuracy_mean": 0.8960416666666666,
      "partial_balanced_accuracy_std": 0.005208333333333315,
      "partial_balanced_accuracy_values": [
        0.90125,
        0.8908333333333334
      ],
      "partial_adj_balanced_accuracy_mean": 0.7920833333333334,
      "partial_adj_balanced_accuracy_std": 0.01041666666666663,
      "partial_adj_balanced_accuracy_values": [
        0.8025,
        0.7816666666666667
      ]
    },
    {
      "step": 3,
      "num_instructions": 3,
      "md5_hashes": [
        "320e7841b0256053dfac19c0b31e76ca",
        "c74e3f0d229af6273f7940820525e811",
        "3550efea3dc6948e0ff473adfc3afd08"
      ],
      "combined_scores_mean": 0.7667927629750867,
      "combined_scores_std": 0.026377429601985986,
      "combined_scores_values": [
        0.8015325141515948,
        0.761192146274176,
        0.737653628499489
      ],
      "word_counts_mean": 78.0,
      "word_counts_std": 2.943920288775949,
      "word_counts_values": [
        79,
        81,
        74
      ],
      "cancel_precision_mean": 0.9592741519744304,
      "cancel_precision_std": 0.01918443956556792,
      "cancel_precision_values": [
        0.9344262295081968,
        0.9622641509433962,
        0.9811320754716981
      ],
      "cancel_recall_mean": 0.8888888888888888,
      "cancel_recall_std": 0.04374448818895449,
      "cancel_recall_values": [
        0.95,
        0.85,
        0.8666666666666667
      ],
      "cancel_f1_mean": 0.9217192032960336,
      "cancel_f1_std": 0.01615218806247158,
      "cancel_f1_values": [
        0.9421487603305785,
        0.9026548672566371,
        0.9203539823008849
      ],
      "cancel_accuracy_mean": 0.9567307692307692,
      "cancel_accuracy_std": 0.007850928662766614,
      "cancel_accuracy_values": [
        0.9663461538461539,
        0.9471153846153846,
        0.9567307692307693
      ],
      "cancel_balanced_accuracy_mean": 0.9365615615615616,
      "cancel_balanced_accuracy_std": 0.018261616571184115,
      "cancel_balanced_accuracy_values": [
        0.9614864864864865,
        0.9182432432432432,
        0.929954954954955
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8731231231231232,
      "cancel_adj_balanced_accuracy_std": 0.036523233142368224,
      "cancel_adj_balanced_accuracy_values": [
        0.922972972972973,
        0.8364864864864865,
        0.8599099099099099
      ],
      "partial_precision_mean": 0.9904761904761905,
      "partial_precision_std": 0.01346870059402948,
      "partial_precision_values": [
        1.0,
        0.9714285714285714,
        1.0
      ],
      "partial_recall_mean": 0.6875,
      "partial_recall_std": 0.02946278254943948,
      "partial_recall_values": [
        0.7083333333333334,
        0.7083333333333334,
        0.6458333333333334
      ],
      "partial_f1_mean": 0.8111185092329801,
      "partial_f1_std": 0.019044757615454665,
      "partial_f1_values": [
        0.8292682926829268,
        0.8192771084337349,
        0.7848101265822784
      ],
      "partial_accuracy_mean": 0.8963963963963963,
      "partial_accuracy_std": 0.008427156276517899,
      "partial_accuracy_values": [
        0.9054054054054054,
        0.8986486486486487,
        0.8851351351351351
      ],
      "partial_balanced_accuracy_mean": 0.8420833333333334,
      "partial_balanced_accuracy_std": 0.013705736836165421,
      "partial_balanced_accuracy_values": [
        0.8541666666666667,
        0.8491666666666666,
        0.8229166666666667
      ],
      "partial_adj_balanced_accuracy_mean": 0.6841666666666667,
      "partial_adj_balanced_accuracy_std": 0.027411473672330842,
      "partial_adj_balanced_accuracy_values": [
        0.7083333333333335,
        0.6983333333333333,
        0.6458333333333335
      ]
    },
    {
      "step": 4,
      "num_instructions": 3,
      "md5_hashes": [
        "ceaa0cd4f4e0420322a1a934a9f88882",
        "96147268b86755769f9ddce481ffea54",
        "f5a7d34d382a198f068bf4c817027510"
      ],
      "combined_scores_mean": 0.816268865051632,
      "combined_scores_std": 0.013908129958738302,
      "combined_scores_values": [
        0.815779331053771,
        0.833542266340265,
        0.7994849977608598
      ],
      "word_counts_mean": 79.33333333333333,
      "word_counts_std": 3.858612300930075,
      "word_counts_values": [
        74,
        81,
        83
      ],
      "cancel_precision_mean": 0.8884408602150539,
      "cancel_precision_std": 0.011562265143874489,
      "cancel_precision_values": [
        0.875,
        0.9032258064516129,
        0.8870967741935484
      ],
      "cancel_recall_mean": 0.9277777777777777,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9166666666666666
      ],
      "cancel_f1_mean": 0.9076326458663847,
      "cancel_f1_std": 0.0073824754420489915,
      "cancel_f1_values": [
        0.9032258064516129,
        0.9180327868852459,
        0.9016393442622951
      ],
      "cancel_accuracy_mean": 0.9455128205128206,
      "cancel_accuracy_std": 0.004532735776836827,
      "cancel_accuracy_values": [
        0.9423076923076923,
        0.9519230769230769,
        0.9423076923076923
      ],
      "cancel_balanced_accuracy_mean": 0.9402402402402402,
      "cancel_balanced_accuracy_std": 0.004800110319262996,
      "cancel_balanced_accuracy_values": [
        0.9396396396396396,
        0.9463963963963964,
        0.9346846846846847
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8804804804804803,
      "cancel_adj_balanced_accuracy_std": 0.009600220638525992,
      "cancel_adj_balanced_accuracy_values": [
        0.8792792792792792,
        0.8927927927927928,
        0.8693693693693694
      ],
      "partial_precision_mean": 0.973672052619421,
      "partial_precision_std": 0.0005658980011300244,
      "partial_precision_values": [
        0.9736842105263158,
        0.9743589743589743,
        0.972972972972973
      ],
      "partial_recall_mean": 0.7708333333333334,
      "partial_recall_std": 0.01701034543599428,
      "partial_recall_values": [
        0.7708333333333334,
        0.7916666666666666,
        0.75
      ],
      "partial_f1_mean": 0.8603623860664288,
      "partial_f1_std": 0.010820617723112342,
      "partial_f1_values": [
        0.8604651162790697,
        0.8735632183908046,
        0.8470588235294118
      ],
      "partial_accuracy_mean": 0.918918918918919,
      "partial_accuracy_std": 0.0055168687900521915,
      "partial_accuracy_values": [
        0.918918918918919,
        0.9256756756756757,
        0.9121621621621622
      ],
      "partial_balanced_accuracy_mean": 0.8804166666666666,
      "partial_balanced_accuracy_std": 0.008505172717997162,
      "partial_balanced_accuracy_values": [
        0.8804166666666666,
        0.8908333333333334,
        0.87
      ],
      "partial_adj_balanced_accuracy_mean": 0.7608333333333333,
      "partial_adj_balanced_accuracy_std": 0.017010345435994324,
      "partial_adj_balanced_accuracy_values": [
        0.7608333333333333,
        0.7816666666666667,
        0.74
      ]
    },
    {
      "step": 5,
      "num_instructions": 3,
      "md5_hashes": [
        "8e5544a3fcd55ac9c15f3944538d12e4",
        "3370d1ad8120a6d87e05bef80af1a110",
        "2beaf8fdd046aee1fafd80e8a76c34d5"
      ],
      "combined_scores_mean": 0.8343457912881592,
      "combined_scores_std": 0.011577327131082593,
      "combined_scores_values": [
        0.8489097398925642,
        0.8205853676316484,
        0.833542266340265
      ],
      "word_counts_mean": 73.66666666666667,
      "word_counts_std": 0.9428090415820634,
      "word_counts_values": [
        75,
        73,
        73
      ],
      "cancel_precision_mean": 0.9021681649920676,
      "cancel_precision_std": 0.0007478654481084459,
      "cancel_precision_values": [
        0.9016393442622951,
        0.9016393442622951,
        0.9032258064516129
      ],
      "cancel_recall_mean": 0.9222222222222222,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9166666666666666,
        0.9166666666666666,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9120715350223546,
      "cancel_f1_std": 0.0042152416166113356,
      "cancel_f1_values": [
        0.9090909090909091,
        0.9090909090909091,
        0.9180327868852459
      ],
      "cancel_accuracy_mean": 0.9487179487179486,
      "cancel_accuracy_std": 0.0022663678884184135,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9471153846153846,
        0.9519230769230769
      ],
      "cancel_balanced_accuracy_mean": 0.9408408408408407,
      "cancel_balanced_accuracy_std": 0.003928371006591917,
      "cancel_balanced_accuracy_values": [
        0.9380630630630631,
        0.9380630630630631,
        0.9463963963963964
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8816816816816817,
      "cancel_adj_balanced_accuracy_std": 0.007856742013183834,
      "cancel_adj_balanced_accuracy_values": [
        0.8761261261261262,
        0.8761261261261262,
        0.8927927927927928
      ],
      "partial_precision_mean": 0.9666562434855117,
      "partial_precision_std": 0.01178880681058339,
      "partial_precision_values": [
        0.975609756097561,
        0.95,
        0.9743589743589743
      ],
      "partial_recall_mean": 0.8055555555555555,
      "partial_recall_std": 0.01964185503295969,
      "partial_recall_values": [
        0.8333333333333334,
        0.7916666666666666,
        0.7916666666666666
      ],
      "partial_f1_mean": 0.8786919955071836,
      "partial_f1_std": 0.014836742363713556,
      "partial_f1_values": [
        0.898876404494382,
        0.8636363636363636,
        0.8735632183908046
      ],
      "partial_accuracy_mean": 0.9279279279279279,
      "partial_accuracy_std": 0.008427156276517848,
      "partial_accuracy_values": [
        0.9391891891891891,
        0.918918918918919,
        0.9256756756756757
      ],
      "partial_balanced_accuracy_mean": 0.8961111111111112,
      "partial_balanced_accuracy_std": 0.011187239203112372,
      "partial_balanced_accuracy_values": [
        0.9116666666666666,
        0.8858333333333333,
        0.8908333333333334
      ],
      "partial_adj_balanced_accuracy_mean": 0.7922222222222222,
      "partial_adj_balanced_accuracy_std": 0.022374478406224745,
      "partial_adj_balanced_accuracy_values": [
        0.8233333333333333,
        0.7716666666666665,
        0.7816666666666667
      ]
    },
    {
      "step": 6,
      "num_instructions": 2,
      "md5_hashes": [
        "f09c7f0c9277f865b244588863398910",
        "39c3c8eeb7cf27d0754aa22b356e2e89"
      ],
      "combined_scores_mean": 0.8355112632272573,
      "combined_scores_std": 0.003830826181105196,
      "combined_scores_values": [
        0.8393420894083625,
        0.8316804370461521
      ],
      "word_counts_mean": 73.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        73,
        73
      ],
      "cancel_precision_mean": 0.9468984962406015,
      "cancel_precision_std": 0.00046992481203006475,
      "cancel_precision_values": [
        0.9473684210526315,
        0.9464285714285714
      ],
      "cancel_recall_mean": 0.8916666666666666,
      "cancel_recall_std": 0.00833333333333336,
      "cancel_recall_values": [
        0.9,
        0.8833333333333333
      ],
      "cancel_f1_mean": 0.9184350132625996,
      "cancel_f1_std": 0.004641909814323608,
      "cancel_f1_values": [
        0.9230769230769231,
        0.9137931034482759
      ],
      "cancel_accuracy_mean": 0.9543269230769231,
      "cancel_accuracy_std": 0.002403846153846201,
      "cancel_accuracy_values": [
        0.9567307692307693,
        0.9519230769230769
      ],
      "cancel_balanced_accuracy_mean": 0.9356981981981982,
      "cancel_balanced_accuracy_std": 0.004166666666666652,
      "cancel_balanced_accuracy_values": [
        0.9398648648648649,
        0.9315315315315316
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8713963963963964,
      "cancel_adj_balanced_accuracy_std": 0.008333333333333304,
      "cancel_adj_balanced_accuracy_values": [
        0.8797297297297297,
        0.8630630630630631
      ],
      "partial_precision_mean": 0.975,
      "partial_precision_std": 0.0,
      "partial_precision_values": [
        0.975,
        0.975
      ],
      "partial_recall_mean": 0.8125,
      "partial_recall_std": 0.0,
      "partial_recall_values": [
        0.8125,
        0.8125
      ],
      "partial_f1_mean": 0.8863636363636364,
      "partial_f1_std": 0.0,
      "partial_f1_values": [
        0.8863636363636364,
        0.8863636363636364
      ],
      "partial_accuracy_mean": 0.9324324324324325,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.90125,
      "partial_balanced_accuracy_std": 0.0,
      "partial_balanced_accuracy_values": [
        0.90125,
        0.90125
      ],
      "partial_adj_balanced_accuracy_mean": 0.8025,
      "partial_adj_balanced_accuracy_std": 0.0,
      "partial_adj_balanced_accuracy_values": [
        0.8025,
        0.8025
      ]
    },
    {
      "step": 7,
      "num_instructions": 3,
      "md5_hashes": [
        "c70589fc73edf6292bbfc033957a457e",
        "0e30e36dc37f7753692c2f538f4fd468",
        "a4ed7a66d51d028cd5a1dac1bfe98bc6"
      ],
      "combined_scores_mean": 0.8505639506389379,
      "combined_scores_std": 0.012234727917079725,
      "combined_scores_values": [
        0.8663068376179405,
        0.8489097398925642,
        0.836475274406309
      ],
      "word_counts_mean": 70.66666666666667,
      "word_counts_std": 2.357022603955158,
      "word_counts_values": [
        69,
        69,
        74
      ],
      "cancel_precision_mean": 0.9172918403260165,
      "cancel_precision_std": 0.012488714151229527,
      "cancel_precision_values": [
        0.9322033898305084,
        0.9016393442622951,
        0.9180327868852459
      ],
      "cancel_recall_mean": 0.9222222222222222,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9166666666666666,
        0.9166666666666666,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9196934972336042,
      "cancel_f1_std": 0.007514511993551269,
      "cancel_f1_values": [
        0.9243697478991597,
        0.9090909090909091,
        0.9256198347107438
      ],
      "cancel_accuracy_mean": 0.953525641025641,
      "cancel_accuracy_std": 0.004532735776836879,
      "cancel_accuracy_values": [
        0.9567307692307693,
        0.9471153846153846,
        0.9567307692307693
      ],
      "cancel_balanced_accuracy_mean": 0.9442192192192193,
      "cancel_balanced_accuracy_std": 0.004800110319262996,
      "cancel_balanced_accuracy_values": [
        0.9448198198198199,
        0.9380630630630631,
        0.9497747747747748
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8884384384384386,
      "cancel_adj_balanced_accuracy_std": 0.009600220638525992,
      "cancel_adj_balanced_accuracy_values": [
        0.8896396396396398,
        0.8761261261261262,
        0.8995495495495496
      ],
      "partial_precision_mean": 0.9753864022156705,
      "partial_precision_std": 0.0007642054510471605,
      "partial_precision_values": [
        0.9761904761904762,
        0.975609756097561,
        0.9743589743589743
      ],
      "partial_recall_mean": 0.8263888888888888,
      "partial_recall_std": 0.025983731852596822,
      "partial_recall_values": [
        0.8541666666666666,
        0.8333333333333334,
        0.7916666666666666
      ],
      "partial_f1_mean": 0.8945169113320993,
      "partial_f1_std": 0.01563574851439063,
      "partial_f1_values": [
        0.9111111111111111,
        0.898876404494382,
        0.8735632183908046
      ],
      "partial_accuracy_mean": 0.9369369369369368,
      "partial_accuracy_std": 0.008427156276517888,
      "partial_accuracy_values": [
        0.9459459459459459,
        0.9391891891891891,
        0.9256756756756757
      ],
      "partial_balanced_accuracy_mean": 0.9081944444444444,
      "partial_balanced_accuracy_std": 0.012991865926298403,
      "partial_balanced_accuracy_values": [
        0.9220833333333334,
        0.9116666666666666,
        0.8908333333333334
      ],
      "partial_adj_balanced_accuracy_mean": 0.8163888888888889,
      "partial_adj_balanced_accuracy_std": 0.025983731852596798,
      "partial_adj_balanced_accuracy_values": [
        0.8441666666666667,
        0.8233333333333333,
        0.7816666666666667
      ]
    },
    {
      "step": 8,
      "num_instructions": 3,
      "md5_hashes": [
        "83302b7e0b223b2c3d64c609e87cd0cf",
        "6359ff8e4d2325a7dc0d3d5559d40f19",
        "619c0754603ad70559b865a863b7d16e"
      ],
      "combined_scores_mean": 0.8336097604120255,
      "combined_scores_std": 0.008538521153974533,
      "combined_scores_values": [
        0.8422016513051714,
        0.8366618809290592,
        0.821965749001846
      ],
      "word_counts_mean": 70.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        70,
        70,
        70
      ],
      "cancel_precision_mean": 0.8842592592592592,
      "cancel_precision_std": 0.0065472850109865284,
      "cancel_precision_values": [
        0.8888888888888888,
        0.8888888888888888,
        0.875
      ],
      "cancel_recall_mean": 0.9333333333333332,
      "cancel_recall_std": 1.1102230246251565e-16,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9081213392779088,
      "cancel_f1_std": 0.0034616644589952413,
      "cancel_f1_values": [
        0.9105691056910569,
        0.9105691056910569,
        0.9032258064516129
      ],
      "cancel_accuracy_mean": 0.9455128205128206,
      "cancel_accuracy_std": 0.0022663678884184135,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9471153846153846,
        0.9423076923076923
      ],
      "cancel_balanced_accuracy_mean": 0.9418918918918919,
      "cancel_balanced_accuracy_std": 0.0015925828405103043,
      "cancel_balanced_accuracy_values": [
        0.9430180180180181,
        0.9430180180180181,
        0.9396396396396396
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8837837837837839,
      "cancel_adj_balanced_accuracy_std": 0.0031851656810206086,
      "cancel_adj_balanced_accuracy_values": [
        0.8860360360360362,
        0.8860360360360362,
        0.8792792792792792
      ],
      "partial_precision_mean": 0.9587398373983739,
      "partial_precision_std": 0.011508445257635835,
      "partial_precision_values": [
        0.975,
        0.9512195121951219,
        0.95
      ],
      "partial_recall_mean": 0.8055555555555555,
      "partial_recall_std": 0.009820927516479843,
      "partial_recall_values": [
        0.8125,
        0.8125,
        0.7916666666666666
      ],
      "partial_f1_mean": 0.8754681647940075,
      "partial_f1_std": 0.009301962740124714,
      "partial_f1_values": [
        0.8863636363636364,
        0.8764044943820225,
        0.8636363636363636
      ],
      "partial_accuracy_mean": 0.9256756756756758,
      "partial_accuracy_std": 0.0055168687900521915,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9256756756756757,
        0.918918918918919
      ],
      "partial_balanced_accuracy_mean": 0.8944444444444444,
      "partial_balanced_accuracy_std": 0.006422015567609419,
      "partial_balanced_accuracy_values": [
        0.90125,
        0.89625,
        0.8858333333333333
      ],
      "partial_adj_balanced_accuracy_mean": 0.7888888888888888,
      "partial_adj_balanced_accuracy_std": 0.012844031135218838,
      "partial_adj_balanced_accuracy_values": [
        0.8025,
        0.7925,
        0.7716666666666665
      ]
    },
    {
      "step": 9,
      "num_instructions": 3,
      "md5_hashes": [
        "ed1ea4fb7f3323628260fc9c846851f7",
        "b4f87525da91ef302792944714335100",
        "3d848db12f32d2c142bc7fbdc0104fb2"
      ],
      "combined_scores_mean": 0.8474391897346077,
      "combined_scores_std": 0.006809213547998792,
      "combined_scores_values": [
        0.8452418594146484,
        0.8566573923390554,
        0.8404183174501196
      ],
      "word_counts_mean": 69.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        69,
        69,
        69
      ],
      "cancel_precision_mean": 0.8978494623655914,
      "cancel_precision_std": 0.007603298722435987,
      "cancel_precision_values": [
        0.9032258064516129,
        0.9032258064516129,
        0.8870967741935484
      ],
      "cancel_recall_mean": 0.9277777777777777,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9166666666666666
      ],
      "cancel_f1_mean": 0.912568306010929,
      "cancel_f1_std": 0.007727942963787413,
      "cancel_f1_values": [
        0.9180327868852459,
        0.9180327868852459,
        0.9016393442622951
      ],
      "cancel_accuracy_mean": 0.9487179487179486,
      "cancel_accuracy_std": 0.004532735776836827,
      "cancel_accuracy_values": [
        0.9519230769230769,
        0.9519230769230769,
        0.9423076923076923
      ],
      "cancel_balanced_accuracy_mean": 0.9424924924924926,
      "cancel_balanced_accuracy_std": 0.005520953847102169,
      "cancel_balanced_accuracy_values": [
        0.9463963963963964,
        0.9463963963963964,
        0.9346846846846847
      ],
      "cancel_adj_balanced_accuracy_mean": 0.884984984984985,
      "cancel_adj_balanced_accuracy_std": 0.011041907694204338,
      "cancel_adj_balanced_accuracy_values": [
        0.8927927927927928,
        0.8927927927927928,
        0.8693693693693694
      ],
      "partial_precision_mean": 0.9676635694928377,
      "partial_precision_std": 0.010809308950036171,
      "partial_precision_values": [
        0.975,
        0.975609756097561,
        0.9523809523809523
      ],
      "partial_recall_mean": 0.826388888888889,
      "partial_recall_std": 0.009820927516479845,
      "partial_recall_values": [
        0.8125,
        0.8333333333333334,
        0.8333333333333334
      ],
      "partial_f1_mean": 0.8913763099156357,
      "partial_f1_std": 0.005402640656609684,
      "partial_f1_values": [
        0.8863636363636364,
        0.898876404494382,
        0.8888888888888888
      ],
      "partial_accuracy_mean": 0.9346846846846847,
      "partial_accuracy_std": 0.003185165681020452,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9391891891891891,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.9065277777777778,
      "partial_balanced_accuracy_std": 0.004253720230864862,
      "partial_balanced_accuracy_values": [
        0.90125,
        0.9116666666666666,
        0.9066666666666667
      ],
      "partial_adj_balanced_accuracy_mean": 0.8130555555555556,
      "partial_adj_balanced_accuracy_std": 0.008507440461729724,
      "partial_adj_balanced_accuracy_values": [
        0.8025,
        0.8233333333333333,
        0.8133333333333335
      ]
    },
    {
      "step": 10,
      "num_instructions": 3,
      "md5_hashes": [
        "2aa42077b3eb1aadd82b26298007d67c",
        "14231c5228b1752fe3db9adbd1b7a80e",
        "2cb9b0fab7eb6d66ff8f059a7e5316de"
      ],
      "combined_scores_mean": 0.8465533605510608,
      "combined_scores_std": 0.007445697244532934,
      "combined_scores_values": [
        0.8535346614665683,
        0.8498893995787911,
        0.836236020607823
      ],
      "word_counts_mean": 70.66666666666667,
      "word_counts_std": 4.496912521077347,
      "word_counts_values": [
        67,
        68,
        77
      ],
      "cancel_precision_mean": 0.9059787432084335,
      "cancel_precision_std": 0.012099065212429675,
      "cancel_precision_values": [
        0.8888888888888888,
        0.9152542372881356,
        0.9137931034482759
      ],
      "cancel_recall_mean": 0.9055555555555556,
      "cancel_recall_std": 0.020786985482077466,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9,
        0.8833333333333333
      ],
      "cancel_f1_mean": 0.9054790718823013,
      "cancel_f1_std": 0.005219112219585238,
      "cancel_f1_values": [
        0.9105691056910569,
        0.907563025210084,
        0.8983050847457628
      ],
      "cancel_accuracy_mean": 0.9455128205128206,
      "cancel_accuracy_std": 0.0022663678884184135,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9471153846153846,
        0.9423076923076923
      ],
      "cancel_balanced_accuracy_mean": 0.9336336336336336,
      "cancel_balanced_accuracy_std": 0.007457037562666116,
      "cancel_balanced_accuracy_values": [
        0.9430180180180181,
        0.9331081081081081,
        0.9247747747747748
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8672672672672673,
      "cancel_adj_balanced_accuracy_std": 0.014914075125332231,
      "cancel_adj_balanced_accuracy_values": [
        0.8860360360360362,
        0.8662162162162161,
        0.8495495495495495
      ],
      "partial_precision_mean": 0.9682359614293817,
      "partial_precision_std": 0.010428120425893474,
      "partial_precision_values": [
        0.975609756097561,
        0.9534883720930233,
        0.975609756097561
      ],
      "partial_recall_mean": 0.8402777777777778,
      "partial_recall_std": 0.009820927516479793,
      "partial_recall_values": [
        0.8333333333333334,
        0.8541666666666666,
        0.8333333333333334
      ],
      "partial_f1_mean": 0.8996172366958883,
      "partial_f1_std": 0.0010476949468130306,
      "partial_f1_values": [
        0.898876404494382,
        0.9010989010989011,
        0.898876404494382
      ],
      "partial_accuracy_mean": 0.9391891891891891,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.9391891891891891,
        0.9391891891891891,
        0.9391891891891891
      ],
      "partial_balanced_accuracy_mean": 0.9134722222222221,
      "partial_balanced_accuracy_std": 0.002553441154284735,
      "partial_balanced_accuracy_values": [
        0.9116666666666666,
        0.9170833333333333,
        0.9116666666666666
      ],
      "partial_adj_balanced_accuracy_mean": 0.8269444444444444,
      "partial_adj_balanced_accuracy_std": 0.00510688230856947,
      "partial_adj_balanced_accuracy_values": [
        0.8233333333333333,
        0.8341666666666665,
        0.8233333333333333
      ]
    },
    {
      "step": 11,
      "num_instructions": 1,
      "md5_hashes": [
        "9319a14bfbdb65357e1f0778e4fb3c3a"
      ],
      "combined_scores_mean": 0.8010053619302949,
      "combined_scores_std": 0.0,
      "combined_scores_values": [
        0.8010053619302949
      ],
      "word_counts_mean": 67.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        67
      ],
      "cancel_precision_mean": 0.9310344827586207,
      "cancel_precision_std": 0.0,
      "cancel_precision_values": [
        0.9310344827586207
      ],
      "cancel_recall_mean": 0.9,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9
      ],
      "cancel_f1_mean": 0.9152542372881356,
      "cancel_f1_std": 0.0,
      "cancel_f1_values": [
        0.9152542372881356
      ],
      "cancel_accuracy_mean": 0.9519230769230769,
      "cancel_accuracy_std": 0.0,
      "cancel_accuracy_values": [
        0.9519230769230769
      ],
      "cancel_balanced_accuracy_mean": 0.9364864864864866,
      "cancel_balanced_accuracy_std": 0.0,
      "cancel_balanced_accuracy_values": [
        0.9364864864864866
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8729729729729732,
      "cancel_adj_balanced_accuracy_std": 0.0,
      "cancel_adj_balanced_accuracy_values": [
        0.8729729729729732
      ],
      "partial_precision_mean": 0.972972972972973,
      "partial_precision_std": 0.0,
      "partial_precision_values": [
        0.972972972972973
      ],
      "partial_recall_mean": 0.75,
      "partial_recall_std": 0.0,
      "partial_recall_values": [
        0.75
      ],
      "partial_f1_mean": 0.8470588235294118,
      "partial_f1_std": 0.0,
      "partial_f1_values": [
        0.8470588235294118
      ],
      "partial_accuracy_mean": 0.9121621621621622,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.9121621621621622
      ],
      "partial_balanced_accuracy_mean": 0.87,
      "partial_balanced_accuracy_std": 0.0,
      "partial_balanced_accuracy_values": [
        0.87
      ],
      "partial_adj_balanced_accuracy_mean": 0.74,
      "partial_adj_balanced_accuracy_std": 0.0,
      "partial_adj_balanced_accuracy_values": [
        0.74
      ]
    },
    {
      "step": 12,
      "num_instructions": 3,
      "md5_hashes": [
        "34b8e5d2732b6aad06cd55d7dafbddc7",
        "084a907419a3ed01838edf9f9345907d",
        "0d761888241681b8f6cd3a8d6c57ab89"
      ],
      "combined_scores_mean": 0.8552409354859428,
      "combined_scores_std": 0.014452764616183049,
      "combined_scores_values": [
        0.8753916600210944,
        0.8481294951315628,
        0.8422016513051714
      ],
      "word_counts_mean": 67.66666666666667,
      "word_counts_std": 0.4714045207910317,
      "word_counts_values": [
        68,
        68,
        67
      ],
      "cancel_precision_mean": 0.8888888888888888,
      "cancel_precision_std": 0.0,
      "cancel_precision_values": [
        0.8888888888888888,
        0.8888888888888888,
        0.8888888888888888
      ],
      "cancel_recall_mean": 0.9333333333333332,
      "cancel_recall_std": 1.1102230246251565e-16,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9105691056910569,
      "cancel_f1_std": 0.0,
      "cancel_f1_values": [
        0.9105691056910569,
        0.9105691056910569,
        0.9105691056910569
      ],
      "cancel_accuracy_mean": 0.9471153846153846,
      "cancel_accuracy_std": 0.0,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9471153846153846,
        0.9471153846153846
      ],
      "cancel_balanced_accuracy_mean": 0.9430180180180181,
      "cancel_balanced_accuracy_std": 0.0,
      "cancel_balanced_accuracy_values": [
        0.9430180180180181,
        0.9430180180180181,
        0.9430180180180181
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8860360360360362,
      "cancel_adj_balanced_accuracy_std": 0.0,
      "cancel_adj_balanced_accuracy_values": [
        0.8860360360360362,
        0.8860360360360362,
        0.8860360360360362
      ],
      "partial_precision_mean": 0.9680417128091546,
      "partial_precision_std": 0.011096699483280958,
      "partial_precision_values": [
        0.9767441860465116,
        0.9523809523809523,
        0.975
      ],
      "partial_recall_mean": 0.8402777777777778,
      "partial_recall_std": 0.025983731852596812,
      "partial_recall_values": [
        0.875,
        0.8333333333333334,
        0.8125
      ],
      "partial_f1_mean": 0.8994431494431495,
      "partial_f1_std": 0.016743370174657504,
      "partial_f1_values": [
        0.9230769230769231,
        0.8888888888888888,
        0.8863636363636364
      ],
      "partial_accuracy_mean": 0.9391891891891891,
      "partial_accuracy_std": 0.00955549704306146,
      "partial_accuracy_values": [
        0.9527027027027027,
        0.9324324324324325,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.9134722222222224,
      "partial_balanced_accuracy_std": 0.013635182795860967,
      "partial_balanced_accuracy_values": [
        0.9325,
        0.9066666666666667,
        0.90125
      ],
      "partial_adj_balanced_accuracy_mean": 0.8269444444444445,
      "partial_adj_balanced_accuracy_std": 0.027270365591721933,
      "partial_adj_balanced_accuracy_values": [
        0.865,
        0.8133333333333335,
        0.8025
      ]
    },
    {
      "step": 13,
      "num_instructions": 3,
      "md5_hashes": [
        "3eac3642b00f0eda17eb9ce78f0e5e12",
        "fbf505136724864722fa86c87fde2a52",
        "8bdbb7cfa1ddcd45a69a80c317d29a93"
      ],
      "combined_scores_mean": 0.8634595753678017,
      "combined_scores_std": 0.002928626619491243,
      "combined_scores_values": [
        0.8654341547188468,
        0.8656252300470703,
        0.8593193413374881
      ],
      "word_counts_mean": 69.33333333333333,
      "word_counts_std": 4.0276819911981905,
      "word_counts_values": [
        67,
        66,
        75
      ],
      "cancel_precision_mean": 0.9028536733454766,
      "cancel_precision_std": 0.011928890530897721,
      "cancel_precision_values": [
        0.9016393442622951,
        0.9180327868852459,
        0.8888888888888888
      ],
      "cancel_recall_mean": 0.9277777777777777,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9166666666666666,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9150932831642367,
      "cancel_f1_std": 0.007467819043206999,
      "cancel_f1_values": [
        0.9090909090909091,
        0.9256198347107438,
        0.9105691056910569
      ],
      "cancel_accuracy_mean": 0.9503205128205128,
      "cancel_accuracy_std": 0.004532735776836879,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9567307692307693,
        0.9471153846153846
      ],
      "cancel_balanced_accuracy_mean": 0.9436186186186187,
      "cancel_balanced_accuracy_std": 0.004800110319262991,
      "cancel_balanced_accuracy_values": [
        0.9380630630630631,
        0.9497747747747748,
        0.9430180180180181
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8872372372372374,
      "cancel_adj_balanced_accuracy_std": 0.009600220638525982,
      "cancel_adj_balanced_accuracy_values": [
        0.8761261261261262,
        0.8995495495495496,
        0.8860360360360362
      ],
      "partial_precision_mean": 0.9538407329105003,
      "partial_precision_std": 0.0004983134469249863,
      "partial_precision_values": [
        0.9545454545454546,
        0.9534883720930233,
        0.9534883720930233
      ],
      "partial_recall_mean": 0.861111111111111,
      "partial_recall_std": 0.009820927516479845,
      "partial_recall_values": [
        0.875,
        0.8541666666666666,
        0.8541666666666666
      ],
      "partial_f1_mean": 0.9050804268195572,
      "partial_f1_std": 0.005630727673089212,
      "partial_f1_values": [
        0.9130434782608695,
        0.9010989010989011,
        0.9010989010989011
      ],
      "partial_accuracy_mean": 0.9414414414414414,
      "partial_accuracy_std": 0.003185165681020504,
      "partial_accuracy_values": [
        0.9459459459459459,
        0.9391891891891891,
        0.9391891891891891
      ],
      "partial_balanced_accuracy_mean": 0.9205555555555556,
      "partial_balanced_accuracy_std": 0.004910463758239948,
      "partial_balanced_accuracy_values": [
        0.9275,
        0.9170833333333333,
        0.9170833333333333
      ],
      "partial_adj_balanced_accuracy_mean": 0.841111111111111,
      "partial_adj_balanced_accuracy_std": 0.009820927516479895,
      "partial_adj_balanced_accuracy_values": [
        0.855,
        0.8341666666666665,
        0.8341666666666665
      ]
    },
    {
      "step": 14,
      "num_instructions": 2,
      "md5_hashes": [
        "844928de26ee3e97fe109172f6466b87",
        "bbb5a7dc87138b53c04c389dbc6cf08d"
      ],
      "combined_scores_mean": 0.7978057080178702,
      "combined_scores_std": 0.0013899575130462694,
      "combined_scores_values": [
        0.7964157505048239,
        0.7991956655309165
      ],
      "word_counts_mean": 69.5,
      "word_counts_std": 0.5,
      "word_counts_values": [
        70,
        69
      ],
      "cancel_precision_mean": 0.9091530054644809,
      "cancel_precision_std": 0.007513661202185773,
      "cancel_precision_values": [
        0.9016393442622951,
        0.9166666666666666
      ],
      "cancel_recall_mean": 0.9166666666666666,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9166666666666666,
        0.9166666666666666
      ],
      "cancel_f1_mean": 0.9128787878787878,
      "cancel_f1_std": 0.0037878787878787845,
      "cancel_f1_values": [
        0.9090909090909091,
        0.9166666666666666
      ],
      "cancel_accuracy_mean": 0.9495192307692307,
      "cancel_accuracy_std": 0.0024038461538461453,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9519230769230769
      ],
      "cancel_balanced_accuracy_mean": 0.9397522522522522,
      "cancel_balanced_accuracy_std": 0.0016891891891891442,
      "cancel_balanced_accuracy_values": [
        0.9380630630630631,
        0.9414414414414414
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8795045045045045,
      "cancel_adj_balanced_accuracy_std": 0.0033783783783782884,
      "cancel_adj_balanced_accuracy_values": [
        0.8761261261261262,
        0.8828828828828827
      ],
      "partial_precision_mean": 0.9473684210526315,
      "partial_precision_std": 0.0,
      "partial_precision_values": [
        0.9473684210526315,
        0.9473684210526315
      ],
      "partial_recall_mean": 0.75,
      "partial_recall_std": 0.0,
      "partial_recall_values": [
        0.75,
        0.75
      ],
      "partial_f1_mean": 0.8372093023255814,
      "partial_f1_std": 0.0,
      "partial_f1_values": [
        0.8372093023255814,
        0.8372093023255814
      ],
      "partial_accuracy_mean": 0.9054054054054054,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.9054054054054054,
        0.9054054054054054
      ],
      "partial_balanced_accuracy_mean": 0.865,
      "partial_balanced_accuracy_std": 0.0,
      "partial_balanced_accuracy_values": [
        0.865,
        0.865
      ],
      "partial_adj_balanced_accuracy_mean": 0.73,
      "partial_adj_balanced_accuracy_std": 0.0,
      "partial_adj_balanced_accuracy_values": [
        0.73,
        0.73
      ]
    },
    {
      "step": 15,
      "num_instructions": 2,
      "md5_hashes": [
        "29c0a441558a7f02a12d8419f5fbefe8",
        "827467cc97dccc44837e3a63c333045c"
      ],
      "combined_scores_mean": 0.8515545467800301,
      "combined_scores_std": 0.00945603198144035,
      "combined_scores_values": [
        0.8420985147985898,
        0.8610105787614705
      ],
      "word_counts_mean": 68.5,
      "word_counts_std": 1.5,
      "word_counts_values": [
        70,
        67
      ],
      "cancel_precision_mean": 0.9316189362945646,
      "cancel_precision_std": 0.0005844535359438852,
      "cancel_precision_values": [
        0.9310344827586207,
        0.9322033898305084
      ],
      "cancel_recall_mean": 0.9083333333333333,
      "cancel_recall_std": 0.008333333333333304,
      "cancel_recall_values": [
        0.9,
        0.9166666666666666
      ],
      "cancel_f1_mean": 0.9198119925936477,
      "cancel_f1_std": 0.004557755305512057,
      "cancel_f1_values": [
        0.9152542372881356,
        0.9243697478991597
      ],
      "cancel_accuracy_mean": 0.9543269230769231,
      "cancel_accuracy_std": 0.002403846153846201,
      "cancel_accuracy_values": [
        0.9519230769230769,
        0.9567307692307693
      ],
      "cancel_balanced_accuracy_mean": 0.9406531531531532,
      "cancel_balanced_accuracy_std": 0.004166666666666652,
      "cancel_balanced_accuracy_values": [
        0.9364864864864866,
        0.9448198198198199
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8813063063063065,
      "cancel_adj_balanced_accuracy_std": 0.008333333333333304,
      "cancel_adj_balanced_accuracy_values": [
        0.8729729729729732,
        0.8896396396396398
      ],
      "partial_precision_mean": 0.9529346622369879,
      "partial_precision_std": 0.0005537098560354781,
      "partial_precision_values": [
        0.9523809523809523,
        0.9534883720930233
      ],
      "partial_recall_mean": 0.84375,
      "partial_recall_std": 0.01041666666666663,
      "partial_recall_values": [
        0.8333333333333334,
        0.8541666666666666
      ],
      "partial_f1_mean": 0.8949938949938949,
      "partial_f1_std": 0.006105006105006139,
      "partial_f1_values": [
        0.8888888888888888,
        0.9010989010989011
      ],
      "partial_accuracy_mean": 0.9358108108108107,
      "partial_accuracy_std": 0.003378378378378344,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9391891891891891
      ],
      "partial_balanced_accuracy_mean": 0.911875,
      "partial_balanced_accuracy_std": 0.005208333333333259,
      "partial_balanced_accuracy_values": [
        0.9066666666666667,
        0.9170833333333333
      ],
      "partial_adj_balanced_accuracy_mean": 0.82375,
      "partial_adj_balanced_accuracy_std": 0.010416666666666519,
      "partial_adj_balanced_accuracy_values": [
        0.8133333333333335,
        0.8341666666666665
      ]
    },
    {
      "step": 16,
      "num_instructions": 3,
      "md5_hashes": [
        "b1442789fc7b4cbc6383040c6806e91c",
        "e2c5ae598132f19b4495c8660f53b640",
        "edf7d7d493da959c634ff20367590dfd"
      ],
      "combined_scores_mean": 0.8405127466242979,
      "combined_scores_std": 0.006093495396965929,
      "combined_scores_values": [
        0.8466822462998371,
        0.8426384655316997,
        0.8322175280413568
      ],
      "word_counts_mean": 66.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        66,
        66,
        66
      ],
      "cancel_precision_mean": 0.9121129326047358,
      "cancel_precision_std": 0.007426915496493663,
      "cancel_precision_values": [
        0.9166666666666666,
        0.9180327868852459,
        0.9016393442622951
      ],
      "cancel_recall_mean": 0.9222222222222222,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9166666666666666,
        0.9333333333333333,
        0.9166666666666666
      ],
      "cancel_f1_mean": 0.9171258034894398,
      "cancel_f1_std": 0.006755711188963366,
      "cancel_f1_values": [
        0.9166666666666666,
        0.9256198347107438,
        0.9090909090909091
      ],
      "cancel_accuracy_mean": 0.951923076923077,
      "cancel_accuracy_std": 0.00392546433138333,
      "cancel_accuracy_values": [
        0.9519230769230769,
        0.9567307692307693,
        0.9471153846153846
      ],
      "cancel_balanced_accuracy_mean": 0.9430930930930931,
      "cancel_balanced_accuracy_std": 0.004921856877802938,
      "cancel_balanced_accuracy_values": [
        0.9414414414414414,
        0.9497747747747748,
        0.9380630630630631
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8861861861861863,
      "cancel_adj_balanced_accuracy_std": 0.009843713755605875,
      "cancel_adj_balanced_accuracy_values": [
        0.8828828828828827,
        0.8995495495495496,
        0.8761261261261262
      ],
      "partial_precision_mean": 0.9516066589237321,
      "partial_precision_std": 0.000547508154228836,
      "partial_precision_values": [
        0.9523809523809523,
        0.9512195121951219,
        0.9512195121951219
      ],
      "partial_recall_mean": 0.8194444444444445,
      "partial_recall_std": 0.009820927516479843,
      "partial_recall_values": [
        0.8333333333333334,
        0.8125,
        0.8125
      ],
      "partial_f1_mean": 0.8805659592176446,
      "partial_f1_std": 0.005885200009875514,
      "partial_f1_values": [
        0.8888888888888888,
        0.8764044943820225,
        0.8764044943820225
      ],
      "partial_accuracy_mean": 0.9279279279279279,
      "partial_accuracy_std": 0.003185165681020504,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9256756756756757,
        0.9256756756756757
      ],
      "partial_balanced_accuracy_mean": 0.8997222222222222,
      "partial_balanced_accuracy_std": 0.004910463758239948,
      "partial_balanced_accuracy_values": [
        0.9066666666666667,
        0.89625,
        0.89625
      ],
      "partial_adj_balanced_accuracy_mean": 0.7994444444444445,
      "partial_adj_balanced_accuracy_std": 0.009820927516479895,
      "partial_adj_balanced_accuracy_values": [
        0.8133333333333335,
        0.7925,
        0.7925
      ]
    },
    {
      "step": 17,
      "num_instructions": 2,
      "md5_hashes": [
        "140705f6b8e5fa3f9a843cfa03ce959e",
        "bebd8920a9f8cff617cb67a156068c9c"
      ],
      "combined_scores_mean": 0.8698261949038253,
      "combined_scores_std": 0.012717943446669822,
      "combined_scores_values": [
        0.8825441383504952,
        0.8571082514571555
      ],
      "word_counts_mean": 65.0,
      "word_counts_std": 1.0,
      "word_counts_values": [
        66,
        64
      ],
      "cancel_precision_mean": 0.8891129032258065,
      "cancel_precision_std": 0.014112903225806439,
      "cancel_precision_values": [
        0.875,
        0.9032258064516129
      ],
      "cancel_recall_mean": 0.9333333333333333,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9106292966684294,
      "cancel_f1_std": 0.007403490216816522,
      "cancel_f1_values": [
        0.9032258064516129,
        0.9180327868852459
      ],
      "cancel_accuracy_mean": 0.9471153846153846,
      "cancel_accuracy_std": 0.004807692307692291,
      "cancel_accuracy_values": [
        0.9423076923076923,
        0.9519230769230769
      ],
      "cancel_balanced_accuracy_mean": 0.943018018018018,
      "cancel_balanced_accuracy_std": 0.0033783783783783994,
      "cancel_balanced_accuracy_values": [
        0.9396396396396396,
        0.9463963963963964
      ],
      "cancel_adj_balanced_accuracy_mean": 0.886036036036036,
      "cancel_adj_balanced_accuracy_std": 0.006756756756756799,
      "cancel_adj_balanced_accuracy_values": [
        0.8792792792792792,
        0.8927927927927928
      ],
      "partial_precision_mean": 0.9545454545454546,
      "partial_precision_std": 0.022727272727272763,
      "partial_precision_values": [
        0.9772727272727273,
        0.9318181818181818
      ],
      "partial_recall_mean": 0.875,
      "partial_recall_std": 0.02083333333333337,
      "partial_recall_values": [
        0.8958333333333334,
        0.8541666666666666
      ],
      "partial_f1_mean": 0.9130434782608696,
      "partial_f1_std": 0.02173913043478265,
      "partial_f1_values": [
        0.9347826086956522,
        0.8913043478260869
      ],
      "partial_accuracy_mean": 0.9459459459459459,
      "partial_accuracy_std": 0.013513513513513487,
      "partial_accuracy_values": [
        0.9594594594594594,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.9275,
      "partial_balanced_accuracy_std": 0.015416666666666634,
      "partial_balanced_accuracy_values": [
        0.9429166666666666,
        0.9120833333333334
      ],
      "partial_adj_balanced_accuracy_mean": 0.855,
      "partial_adj_balanced_accuracy_std": 0.030833333333333268,
      "partial_adj_balanced_accuracy_values": [
        0.8858333333333333,
        0.8241666666666667
      ]
    },
    {
      "step": 18,
      "num_instructions": 3,
      "md5_hashes": [
        "a8ed1587d9e643f070c8e2fa051a2d1f",
        "3563a890fa77181c135c3c1ef527bb54",
        "28511cdcb890d87ccd24abfcdb7878ab"
      ],
      "combined_scores_mean": 0.8498430626393484,
      "combined_scores_std": 0.014637531956733806,
      "combined_scores_values": [
        0.8544293800184284,
        0.8650316167477686,
        0.8300681911518482
      ],
      "word_counts_mean": 62.333333333333336,
      "word_counts_std": 0.4714045207910317,
      "word_counts_values": [
        62,
        63,
        62
      ],
      "cancel_precision_mean": 0.8882915173237754,
      "cancel_precision_std": 0.0008448109691595368,
      "cancel_precision_values": [
        0.8888888888888888,
        0.8888888888888888,
        0.8870967741935484
      ],
      "cancel_recall_mean": 0.9277777777777777,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9166666666666666
      ],
      "cancel_f1_mean": 0.9075925185481363,
      "cancel_f1_std": 0.004209529907103687,
      "cancel_f1_values": [
        0.9105691056910569,
        0.9105691056910569,
        0.9016393442622951
      ],
      "cancel_accuracy_mean": 0.9455128205128206,
      "cancel_accuracy_std": 0.0022663678884184135,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9471153846153846,
        0.9423076923076923
      ],
      "cancel_balanced_accuracy_mean": 0.9402402402402403,
      "cancel_balanced_accuracy_std": 0.00392837100659197,
      "cancel_balanced_accuracy_values": [
        0.9430180180180181,
        0.9430180180180181,
        0.9346846846846847
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8804804804804807,
      "cancel_adj_balanced_accuracy_std": 0.00785674201318394,
      "cancel_adj_balanced_accuracy_values": [
        0.8860360360360362,
        0.8860360360360362,
        0.8693693693693694
      ],
      "partial_precision_mean": 0.8997635933806146,
      "partial_precision_std": 0.025276721332621575,
      "partial_precision_values": [
        0.8936170212765957,
        0.9333333333333333,
        0.8723404255319149
      ],
      "partial_recall_mean": 0.8680555555555555,
      "partial_recall_std": 0.009820927516479843,
      "partial_recall_values": [
        0.875,
        0.875,
        0.8541666666666666
      ],
      "partial_f1_mean": 0.8835314091680816,
      "partial_f1_std": 0.016364703630494894,
      "partial_f1_values": [
        0.8842105263157894,
        0.9032258064516129,
        0.8631578947368421
      ],
      "partial_accuracy_mean": 0.9256756756756758,
      "partial_accuracy_std": 0.011033737580104383,
      "partial_accuracy_values": [
        0.9256756756756757,
        0.9391891891891891,
        0.9121621621621622
      ],
      "partial_balanced_accuracy_mean": 0.9106944444444444,
      "partial_balanced_accuracy_std": 0.010454560703643824,
      "partial_balanced_accuracy_values": [
        0.9125,
        0.9225,
        0.8970833333333332
      ],
      "partial_adj_balanced_accuracy_mean": 0.8213888888888888,
      "partial_adj_balanced_accuracy_std": 0.020909121407287647,
      "partial_adj_balanced_accuracy_values": [
        0.825,
        0.845,
        0.7941666666666665
      ]
    },
    {
      "step": 19,
      "num_instructions": 3,
      "md5_hashes": [
        "73635f697e0d92f4da39766e7f224f7f",
        "a18cbbd059f05f64dc79cf92b32edd17",
        "d1fe6497e62c97e55b5516e444d6e2e9"
      ],
      "combined_scores_mean": 0.8429891459225461,
      "combined_scores_std": 0.01238301830560001,
      "combined_scores_values": [
        0.8348935015601683,
        0.8335887667257194,
        0.8604851694817507
      ],
      "word_counts_mean": 69.66666666666667,
      "word_counts_std": 1.247219128924647,
      "word_counts_values": [
        71,
        70,
        68
      ],
      "cancel_precision_mean": 0.8616744366744368,
      "cancel_precision_std": 0.010825192281465881,
      "cancel_precision_values": [
        0.8484848484848485,
        0.875,
        0.8615384615384616
      ],
      "cancel_recall_mean": 0.9333333333333332,
      "cancel_recall_std": 1.1102230246251565e-16,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.8960382317801673,
      "cancel_f1_std": 0.0058530845174060335,
      "cancel_f1_values": [
        0.8888888888888888,
        0.9032258064516129,
        0.896
      ],
      "cancel_accuracy_mean": 0.9359266344636281,
      "cancel_accuracy_std": 0.004496720944096411,
      "cancel_accuracy_values": [
        0.93,
        0.9408866995073891,
        0.9368932038834952
      ],
      "cancel_balanced_accuracy_mean": 0.9351639228351557,
      "cancel_balanced_accuracy_std": 0.003197215642021528,
      "cancel_balanced_accuracy_values": [
        0.930952380952381,
        0.9386946386946387,
        0.9358447488584475
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8703278456703115,
      "cancel_adj_balanced_accuracy_std": 0.006394431284043056,
      "cancel_adj_balanced_accuracy_values": [
        0.861904761904762,
        0.8773892773892773,
        0.871689497716895
      ],
      "partial_precision_mean": 0.966108966108966,
      "partial_precision_std": 0.024108144690222433,
      "partial_precision_values": [
        1.0,
        0.9459459459459459,
        0.9523809523809523
      ],
      "partial_recall_mean": 0.8310141717624022,
      "partial_recall_std": 0.027319624850840555,
      "partial_recall_values": [
        0.8095238095238095,
        0.813953488372093,
        0.8695652173913043
      ],
      "partial_f1_mean": 0.8929425837320575,
      "partial_f1_std": 0.013975264887019036,
      "partial_f1_values": [
        0.8947368421052632,
        0.875,
        0.9090909090909091
      ],
      "partial_accuracy_mean": 0.9393775174597092,
      "partial_accuracy_std": 0.006650917653704258,
      "partial_accuracy_values": [
        0.9428571428571428,
        0.9300699300699301,
        0.9452054794520548
      ],
      "partial_balanced_accuracy_mean": 0.9088404192145344,
      "partial_balanced_accuracy_std": 0.011712307924767781,
      "partial_balanced_accuracy_values": [
        0.9047619047619048,
        0.8969767441860466,
        0.9247826086956521
      ],
      "partial_adj_balanced_accuracy_mean": 0.8176808384290689,
      "partial_adj_balanced_accuracy_std": 0.023424615849535563,
      "partial_adj_balanced_accuracy_values": [
        0.8095238095238095,
        0.7939534883720931,
        0.8495652173913042
      ]
    },
    {
      "step": 20,
      "num_instructions": 3,
      "md5_hashes": [
        "8a217204704f46de1f63d8c8af7e9cbf",
        "d11ba570d8c5afcfbac688c99ad5dcb2",
        "902b618099afa9253fe80a2de3e80341"
      ],
      "combined_scores_mean": 0.857597539489425,
      "combined_scores_std": 0.003217932694426361,
      "combined_scores_values": [
        0.8570114821724165,
        0.861798897567857,
        0.8539822387280015
      ],
      "word_counts_mean": 68.0,
      "word_counts_std": 0.816496580927726,
      "word_counts_values": [
        67,
        69,
        68
      ],
      "cancel_precision_mean": 0.8836618876941458,
      "cancel_precision_std": 0.006168421872181401,
      "cancel_precision_values": [
        0.8870967741935484,
        0.875,
        0.8888888888888888
      ],
      "cancel_recall_mean": 0.9277777777777777,
      "cancel_recall_std": 0.007856742013183886,
      "cancel_recall_values": [
        0.9166666666666666,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9051447521349884,
      "cancel_f1_std": 0.003889894959632306,
      "cancel_f1_values": [
        0.9016393442622951,
        0.9032258064516129,
        0.9105691056910569
      ],
      "cancel_accuracy_mean": 0.9439102564102564,
      "cancel_accuracy_std": 0.0022663678884184135,
      "cancel_accuracy_values": [
        0.9423076923076923,
        0.9423076923076923,
        0.9471153846153846
      ],
      "cancel_balanced_accuracy_mean": 0.9391141141141142,
      "cancel_balanced_accuracy_std": 0.0034223036997121847,
      "cancel_balanced_accuracy_values": [
        0.9346846846846847,
        0.9396396396396396,
        0.9430180180180181
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8782282282282283,
      "cancel_adj_balanced_accuracy_std": 0.006844607399424369,
      "cancel_adj_balanced_accuracy_values": [
        0.8693693693693694,
        0.8792792792792792,
        0.8860360360360362
      ],
      "partial_precision_mean": 0.9328282828282828,
      "partial_precision_std": 0.0007142492739258364,
      "partial_precision_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9318181818181818
      ],
      "partial_recall_mean": 0.8680555555555555,
      "partial_recall_std": 0.009820927516479843,
      "partial_recall_values": [
        0.875,
        0.875,
        0.8541666666666666
      ],
      "partial_f1_mean": 0.8992519869097709,
      "partial_f1_std": 0.0056198294904961765,
      "partial_f1_values": [
        0.9032258064516129,
        0.9032258064516129,
        0.8913043478260869
      ],
      "partial_accuracy_mean": 0.9369369369369368,
      "partial_accuracy_std": 0.003185165681020452,
      "partial_accuracy_values": [
        0.9391891891891891,
        0.9391891891891891,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.9190277777777777,
      "partial_balanced_accuracy_std": 0.004910463758239896,
      "partial_balanced_accuracy_values": [
        0.9225,
        0.9225,
        0.9120833333333334
      ],
      "partial_adj_balanced_accuracy_mean": 0.8380555555555556,
      "partial_adj_balanced_accuracy_std": 0.009820927516479791,
      "partial_adj_balanced_accuracy_values": [
        0.845,
        0.845,
        0.8241666666666667
      ]
    },
    {
      "step": 21,
      "num_instructions": 2,
      "md5_hashes": [
        "4026e2593a87ddc930c6009d789fa1b3",
        "6651df7c4e5c1b78547c43d75bf577a9"
      ],
      "combined_scores_mean": 0.8247793795148244,
      "combined_scores_std": 0.01624776883917306,
      "combined_scores_values": [
        0.8085316106756513,
        0.8410271483539974
      ],
      "word_counts_mean": 64.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        64,
        64
      ],
      "cancel_precision_mean": 0.814262023217247,
      "cancel_precision_std": 0.03648424543946932,
      "cancel_precision_values": [
        0.7777777777777778,
        0.8507462686567164
      ],
      "cancel_recall_mean": 0.9416666666666667,
      "cancel_recall_std": 0.008333333333333304,
      "cancel_recall_values": [
        0.9333333333333333,
        0.95
      ],
      "cancel_f1_mean": 0.8730613218802195,
      "cancel_f1_std": 0.024576473395371,
      "cancel_f1_values": [
        0.8484848484848485,
        0.8976377952755905
      ],
      "cancel_accuracy_mean": 0.9206730769230769,
      "cancel_accuracy_std": 0.016826923076923073,
      "cancel_accuracy_values": [
        0.9038461538461539,
        0.9375
      ],
      "cancel_balanced_accuracy_mean": 0.9269144144144144,
      "cancel_balanced_accuracy_std": 0.014301801801801795,
      "cancel_balanced_accuracy_values": [
        0.9126126126126126,
        0.9412162162162162
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8538288288288288,
      "cancel_adj_balanced_accuracy_std": 0.02860360360360359,
      "cancel_adj_balanced_accuracy_values": [
        0.8252252252252252,
        0.8824324324324324
      ],
      "partial_precision_mean": 0.9407260351673283,
      "partial_precision_std": 0.010493477027793519,
      "partial_precision_values": [
        0.9512195121951219,
        0.9302325581395349
      ],
      "partial_recall_mean": 0.8229166666666667,
      "partial_recall_std": 0.010416666666666685,
      "partial_recall_values": [
        0.8125,
        0.8333333333333334
      ],
      "partial_f1_mean": 0.8777626867514507,
      "partial_f1_std": 0.0013581923694283016,
      "partial_f1_values": [
        0.8764044943820225,
        0.8791208791208791
      ],
      "partial_accuracy_mean": 0.9256756756756757,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.9256756756756757,
        0.9256756756756757
      ],
      "partial_balanced_accuracy_mean": 0.8989583333333333,
      "partial_balanced_accuracy_std": 0.0027083333333333126,
      "partial_balanced_accuracy_values": [
        0.89625,
        0.9016666666666666
      ],
      "partial_adj_balanced_accuracy_mean": 0.7979166666666666,
      "partial_adj_balanced_accuracy_std": 0.005416666666666625,
      "partial_adj_balanced_accuracy_values": [
        0.7925,
        0.8033333333333332
      ]
    },
    {
      "step": 22,
      "num_instructions": 4,
      "md5_hashes": [
        "e86ce75b3cdcb15d3a8804a333cca3b2",
        "66c201a15fd2550e120736779c0edc9d",
        "8264fe8010a9b8f3297fb2b48fd4fc84",
        "6b75d96290c0ede2c82cbf0b1e8b4891"
      ],
      "combined_scores_mean": 0.8567346789813324,
      "combined_scores_std": 0.008160792122464011,
      "combined_scores_values": [
        0.8687449770564902,
        0.8589891150933585,
        0.85237025783297,
        0.8468343659425107
      ],
      "word_counts_mean": 66.5,
      "word_counts_std": 0.5,
      "word_counts_values": [
        67,
        66,
        66,
        67
      ],
      "cancel_precision_mean": 0.8391774160869858,
      "cancel_precision_std": 0.013851072643970517,
      "cancel_precision_values": [
        0.8615384615384616,
        0.8235294117647058,
        0.835820895522388,
        0.835820895522388
      ],
      "cancel_recall_mean": 0.9333333333333333,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.8836948818897639,
      "cancel_f1_std": 0.007640906450932567,
      "cancel_f1_values": [
        0.896,
        0.875,
        0.8818897637795275,
        0.8818897637795275
      ],
      "cancel_accuracy_mean": 0.9290865384615384,
      "cancel_accuracy_std": 0.005239061230217137,
      "cancel_accuracy_values": [
        0.9375,
        0.9230769230769231,
        0.9278846153846154,
        0.9278846153846154
      ],
      "cancel_balanced_accuracy_mean": 0.9303490990990991,
      "cancel_balanced_accuracy_std": 0.003681502486098533,
      "cancel_balanced_accuracy_values": [
        0.9362612612612613,
        0.9261261261261262,
        0.9295045045045045,
        0.9295045045045045
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8606981981981983,
      "cancel_adj_balanced_accuracy_std": 0.007363004972197066,
      "cancel_adj_balanced_accuracy_values": [
        0.8725225225225226,
        0.8522522522522524,
        0.859009009009009,
        0.859009009009009
      ],
      "partial_precision_mean": 0.9301009015840918,
      "partial_precision_std": 0.030260272186352858,
      "partial_precision_values": [
        0.9767441860465116,
        0.9347826086956522,
        0.8958333333333334,
        0.9130434782608695
      ],
      "partial_recall_mean": 0.8854166666666667,
      "partial_recall_std": 0.010416666666666685,
      "partial_recall_values": [
        0.875,
        0.8958333333333334,
        0.8958333333333334,
        0.875
      ],
      "partial_f1_mean": 0.9068552236770322,
      "partial_f1_std": 0.012494912649961366,
      "partial_f1_values": [
        0.9230769230769231,
        0.9148936170212766,
        0.8958333333333334,
        0.8936170212765957
      ],
      "partial_accuracy_mean": 0.9408783783783784,
      "partial_accuracy_std": 0.008777284497815258,
      "partial_accuracy_values": [
        0.9527027027027027,
        0.9459459459459459,
        0.9324324324324325,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.9264583333333333,
      "partial_balanced_accuracy_std": 0.006538481177698008,
      "partial_balanced_accuracy_values": [
        0.9325,
        0.9329166666666666,
        0.9229166666666666,
        0.9175
      ],
      "partial_adj_balanced_accuracy_mean": 0.8529166666666665,
      "partial_adj_balanced_accuracy_std": 0.013076962355396016,
      "partial_adj_balanced_accuracy_values": [
        0.865,
        0.8658333333333332,
        0.8458333333333332,
        0.835
      ]
    },
    {
      "step": 23,
      "num_instructions": 4,
      "md5_hashes": [
        "6d91b124330003bd79f3c2f7012e1ab7",
        "b85a8b71582eb5a7641389acbb919d02",
        "5810a0928af9b4f07c6ec4d8b38211a1",
        "a018c17bcbbe2e8d355b4b29a1aede46"
      ],
      "combined_scores_mean": 0.8346562495309213,
      "combined_scores_std": 0.018738760422218365,
      "combined_scores_values": [
        0.8128592637534875,
        0.8305854919014307,
        0.8645947505673364,
        0.8305854919014307
      ],
      "word_counts_mean": 64.0,
      "word_counts_std": 1.0,
      "word_counts_values": [
        65,
        63,
        63,
        65
      ],
      "cancel_precision_mean": 0.882051282051282,
      "cancel_precision_std": 0.01184308244491536,
      "cancel_precision_values": [
        0.8615384615384616,
        0.8888888888888888,
        0.8888888888888888,
        0.8888888888888888
      ],
      "cancel_recall_mean": 0.9333333333333333,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9069268292682927,
      "cancel_f1_std": 0.006308607819437835,
      "cancel_f1_values": [
        0.896,
        0.9105691056910569,
        0.9105691056910569,
        0.9105691056910569
      ],
      "cancel_accuracy_mean": 0.9447115384615384,
      "cancel_accuracy_std": 0.004163583672040556,
      "cancel_accuracy_values": [
        0.9375,
        0.9471153846153846,
        0.9471153846153846,
        0.9471153846153846
      ],
      "cancel_balanced_accuracy_mean": 0.941328828828829,
      "cancel_balanced_accuracy_std": 0.0029257614992717704,
      "cancel_balanced_accuracy_values": [
        0.9362612612612613,
        0.9430180180180181,
        0.9430180180180181,
        0.9430180180180181
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8826576576576578,
      "cancel_adj_balanced_accuracy_std": 0.005851522998543541,
      "cancel_adj_balanced_accuracy_values": [
        0.8725225225225226,
        0.8860360360360362,
        0.8860360360360362,
        0.8860360360360362
      ],
      "partial_precision_mean": 0.9746481588586852,
      "partial_precision_std": 0.0009320936767791304,
      "partial_precision_values": [
        0.9736842105263158,
        0.9743589743589743,
        0.9761904761904762,
        0.9743589743589743
      ],
      "partial_recall_mean": 0.8020833333333333,
      "partial_recall_std": 0.03124999999999998,
      "partial_recall_values": [
        0.7708333333333334,
        0.7916666666666666,
        0.8541666666666666,
        0.7916666666666666
      ],
      "partial_f1_mean": 0.8796756660429474,
      "partial_f1_std": 0.018920600290849177,
      "partial_f1_values": [
        0.8604651162790697,
        0.8735632183908046,
        0.9111111111111111,
        0.8735632183908046
      ],
      "partial_accuracy_mean": 0.9290540540540542,
      "partial_accuracy_std": 0.010135135135135124,
      "partial_accuracy_values": [
        0.918918918918919,
        0.9256756756756757,
        0.9459459459459459,
        0.9256756756756757
      ],
      "partial_balanced_accuracy_mean": 0.8960416666666666,
      "partial_balanced_accuracy_std": 0.015625000000000017,
      "partial_balanced_accuracy_values": [
        0.8804166666666666,
        0.8908333333333334,
        0.9220833333333334,
        0.8908333333333334
      ],
      "partial_adj_balanced_accuracy_mean": 0.7920833333333334,
      "partial_adj_balanced_accuracy_std": 0.031250000000000035,
      "partial_adj_balanced_accuracy_values": [
        0.7608333333333333,
        0.7816666666666667,
        0.8441666666666667,
        0.7816666666666667
      ]
    },
    {
      "step": 24,
      "num_instructions": 3,
      "md5_hashes": [
        "6651df7c4e5c1b78547c43d75bf577a9",
        "c5a33f47744fe832e6c6547e31df8865",
        "de2a064431eea988661d134c0192c5c6"
      ],
      "combined_scores_mean": 0.8401970444118386,
      "combined_scores_std": 0.0035069882231068415,
      "combined_scores_values": [
        0.8410271483539974,
        0.8440165697726101,
        0.8355474151089085
      ],
      "word_counts_mean": 64.33333333333333,
      "word_counts_std": 0.4714045207910317,
      "word_counts_values": [
        64,
        64,
        65
      ],
      "cancel_precision_mean": 0.8450173375546509,
      "cancel_precision_std": 0.006568075052251481,
      "cancel_precision_values": [
        0.8507462686567164,
        0.8484848484848485,
        0.835820895522388
      ],
      "cancel_recall_mean": 0.9388888888888888,
      "cancel_recall_std": 0.007856742013183832,
      "cancel_recall_values": [
        0.95,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.889472149314669,
      "cancel_f1_std": 0.00644232196977967,
      "cancel_f1_values": [
        0.8976377952755905,
        0.8888888888888888,
        0.8818897637795275
      ],
      "cancel_accuracy_mean": 0.9326923076923078,
      "cancel_accuracy_std": 0.0039254643313832846,
      "cancel_accuracy_values": [
        0.9375,
        0.9326923076923077,
        0.9278846153846154
      ],
      "cancel_balanced_accuracy_mean": 0.9345345345345345,
      "cancel_balanced_accuracy_std": 0.0049218568778029255,
      "cancel_balanced_accuracy_values": [
        0.9412162162162162,
        0.9328828828828829,
        0.9295045045045045
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8690690690690691,
      "cancel_adj_balanced_accuracy_std": 0.009843713755605853,
      "cancel_adj_balanced_accuracy_values": [
        0.8824324324324324,
        0.8657657657657658,
        0.859009009009009
      ],
      "partial_precision_mean": 0.9527410888726827,
      "partial_precision_std": 0.01852691370862002,
      "partial_precision_values": [
        0.9302325581395349,
        0.975609756097561,
        0.9523809523809523
      ],
      "partial_recall_mean": 0.8333333333333334,
      "partial_recall_std": 0.0,
      "partial_recall_values": [
        0.8333333333333334,
        0.8333333333333334,
        0.8333333333333334
      ],
      "partial_f1_mean": 0.8889620575013834,
      "partial_f1_std": 0.008065325409023903,
      "partial_f1_values": [
        0.8791208791208791,
        0.898876404494382,
        0.8888888888888888
      ],
      "partial_accuracy_mean": 0.9324324324324325,
      "partial_accuracy_std": 0.0055168687900521915,
      "partial_accuracy_values": [
        0.9256756756756757,
        0.9391891891891891,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.9066666666666666,
      "partial_balanced_accuracy_std": 0.004082482904638634,
      "partial_balanced_accuracy_values": [
        0.9016666666666666,
        0.9116666666666666,
        0.9066666666666667
      ],
      "partial_adj_balanced_accuracy_mean": 0.8133333333333334,
      "partial_adj_balanced_accuracy_std": 0.008164965809277268,
      "partial_adj_balanced_accuracy_values": [
        0.8033333333333332,
        0.8233333333333333,
        0.8133333333333335
      ]
    },
    {
      "step": 25,
      "num_instructions": 4,
      "md5_hashes": [
        "c1ec57716fa9b83a72e86cb7f73a0ad0",
        "6413c85626107f3bac39df4b05b562c5",
        "c81414cf6efa758a68dc83415dee464d",
        "fddb6c6930b36bce9f08c34a2eaa1681"
      ],
      "combined_scores_mean": 0.8538335056481177,
      "combined_scores_std": 0.013650955516489746,
      "combined_scores_values": [
        0.8340529648819804,
        0.8482579296290906,
        0.867397898034329,
        0.8656252300470703
      ],
      "word_counts_mean": 68.25,
      "word_counts_std": 1.0897247358851685,
      "word_counts_values": [
        67,
        70,
        68,
        68
      ],
      "cancel_precision_mean": 0.892610143442623,
      "cancel_precision_std": 0.026015925463756622,
      "cancel_precision_values": [
        0.859375,
        0.9180327868852459,
        0.875,
        0.9180327868852459
      ],
      "cancel_recall_mean": 0.9291666666666667,
      "cancel_recall_std": 0.0072168783648703435,
      "cancel_recall_values": [
        0.9166666666666666,
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9103905625166623,
      "cancel_f1_std": 0.016261886168557987,
      "cancel_f1_values": [
        0.8870967741935484,
        0.9256198347107438,
        0.9032258064516129,
        0.9256198347107438
      ],
      "cancel_accuracy_mean": 0.9471153846153846,
      "cancel_accuracy_std": 0.010198655497882913,
      "cancel_accuracy_values": [
        0.9326923076923077,
        0.9567307692307693,
        0.9423076923076923,
        0.9567307692307693
      ],
      "cancel_balanced_accuracy_mean": 0.9417792792792792,
      "cancel_balanced_accuracy_std": 0.009004080859297625,
      "cancel_balanced_accuracy_values": [
        0.9279279279279279,
        0.9497747747747748,
        0.9396396396396396,
        0.9497747747747748
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8835585585585586,
      "cancel_adj_balanced_accuracy_std": 0.018008161718595248,
      "cancel_adj_balanced_accuracy_values": [
        0.8558558558558558,
        0.8995495495495496,
        0.8792792792792792,
        0.8995495495495496
      ],
      "partial_precision_mean": 0.948940735373813,
      "partial_precision_std": 0.021626416911704204,
      "partial_precision_values": [
        0.9523809523809523,
        0.975,
        0.9148936170212766,
        0.9534883720930233
      ],
      "partial_recall_mean": 0.8489583333333334,
      "partial_recall_std": 0.030812915536977174,
      "partial_recall_values": [
        0.8333333333333334,
        0.8125,
        0.8958333333333334,
        0.8541666666666666
      ],
      "partial_f1_mean": 0.8954036460615408,
      "partial_f1_std": 0.007965703670836906,
      "partial_f1_values": [
        0.8888888888888888,
        0.8863636363636364,
        0.9052631578947369,
        0.9010989010989011
      ],
      "partial_accuracy_mean": 0.9358108108108107,
      "partial_accuracy_std": 0.003378378378378344,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9324324324324325,
        0.9391891891891891,
        0.9391891891891891
      ],
      "partial_balanced_accuracy_mean": 0.9132291666666668,
      "partial_balanced_accuracy_std": 0.010212052893789555,
      "partial_balanced_accuracy_values": [
        0.9066666666666667,
        0.90125,
        0.9279166666666667,
        0.9170833333333333
      ],
      "partial_adj_balanced_accuracy_mean": 0.8264583333333333,
      "partial_adj_balanced_accuracy_std": 0.02042410578757911,
      "partial_adj_balanced_accuracy_values": [
        0.8133333333333335,
        0.8025,
        0.8558333333333334,
        0.8341666666666665
      ]
    },
    {
      "step": 26,
      "num_instructions": 2,
      "md5_hashes": [
        "aefc6b6f50d19260bc4787562bdae79a",
        "ffca9dd24cf66aa35be0db64faaf6bf0"
      ],
      "combined_scores_mean": 0.8599007458679677,
      "combined_scores_std": 0.0037716485937150934,
      "combined_scores_values": [
        0.8561290972742527,
        0.8636723944616829
      ],
      "word_counts_mean": 68.0,
      "word_counts_std": 1.0,
      "word_counts_values": [
        67,
        69
      ],
      "cancel_precision_mean": 0.8682692307692308,
      "cancel_precision_std": 0.006730769230769207,
      "cancel_precision_values": [
        0.875,
        0.8615384615384616
      ],
      "cancel_recall_mean": 0.9333333333333333,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.8996129032258064,
      "cancel_f1_std": 0.0036129032258064298,
      "cancel_f1_values": [
        0.9032258064516129,
        0.896
      ],
      "cancel_accuracy_mean": 0.9399038461538461,
      "cancel_accuracy_std": 0.0024038461538461453,
      "cancel_accuracy_values": [
        0.9423076923076923,
        0.9375
      ],
      "cancel_balanced_accuracy_mean": 0.9379504504504504,
      "cancel_balanced_accuracy_std": 0.0016891891891891442,
      "cancel_balanced_accuracy_values": [
        0.9396396396396396,
        0.9362612612612613
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8759009009009009,
      "cancel_adj_balanced_accuracy_std": 0.0033783783783782884,
      "cancel_adj_balanced_accuracy_values": [
        0.8792792792792792,
        0.8725225225225226
      ],
      "partial_precision_mean": 0.9540169133192389,
      "partial_precision_std": 0.0005285412262156508,
      "partial_precision_values": [
        0.9534883720930233,
        0.9545454545454546
      ],
      "partial_recall_mean": 0.8645833333333333,
      "partial_recall_std": 0.010416666666666685,
      "partial_recall_values": [
        0.8541666666666666,
        0.875
      ],
      "partial_f1_mean": 0.9070711896798853,
      "partial_f1_std": 0.0059722885809841975,
      "partial_f1_values": [
        0.9010989010989011,
        0.9130434782608695
      ],
      "partial_accuracy_mean": 0.9425675675675675,
      "partial_accuracy_std": 0.0033783783783783994,
      "partial_accuracy_values": [
        0.9391891891891891,
        0.9459459459459459
      ],
      "partial_balanced_accuracy_mean": 0.9222916666666666,
      "partial_balanced_accuracy_std": 0.00520833333333337,
      "partial_balanced_accuracy_values": [
        0.9170833333333333,
        0.9275
      ],
      "partial_adj_balanced_accuracy_mean": 0.8445833333333332,
      "partial_adj_balanced_accuracy_std": 0.01041666666666674,
      "partial_adj_balanced_accuracy_values": [
        0.8341666666666665,
        0.855
      ]
    },
    {
      "step": 27,
      "num_instructions": 2,
      "md5_hashes": [
        "afd9cbb93c167e89b8c817a477e7fb08",
        "dee539e43f650f83265db95980aa5b02"
      ],
      "combined_scores_mean": 0.8434552639864457,
      "combined_scores_std": 0.0015663810351995155,
      "combined_scores_values": [
        0.8450216450216451,
        0.8418888829512461
      ],
      "word_counts_mean": 68.0,
      "word_counts_std": 0.0,
      "word_counts_values": [
        68,
        68
      ],
      "cancel_precision_mean": 0.8682692307692308,
      "cancel_precision_std": 0.006730769230769207,
      "cancel_precision_values": [
        0.875,
        0.8615384615384616
      ],
      "cancel_recall_mean": 0.9333333333333333,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.8996129032258064,
      "cancel_f1_std": 0.0036129032258064298,
      "cancel_f1_values": [
        0.9032258064516129,
        0.896
      ],
      "cancel_accuracy_mean": 0.9399038461538461,
      "cancel_accuracy_std": 0.0024038461538461453,
      "cancel_accuracy_values": [
        0.9423076923076923,
        0.9375
      ],
      "cancel_balanced_accuracy_mean": 0.9379504504504504,
      "cancel_balanced_accuracy_std": 0.0016891891891891442,
      "cancel_balanced_accuracy_values": [
        0.9396396396396396,
        0.9362612612612613
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8759009009009009,
      "cancel_adj_balanced_accuracy_std": 0.0033783783783782884,
      "cancel_adj_balanced_accuracy_values": [
        0.8792792792792792,
        0.8725225225225226
      ],
      "partial_precision_mean": 0.9523809523809523,
      "partial_precision_std": 0.0,
      "partial_precision_values": [
        0.9523809523809523,
        0.9523809523809523
      ],
      "partial_recall_mean": 0.8333333333333334,
      "partial_recall_std": 0.0,
      "partial_recall_values": [
        0.8333333333333334,
        0.8333333333333334
      ],
      "partial_f1_mean": 0.8888888888888888,
      "partial_f1_std": 0.0,
      "partial_f1_values": [
        0.8888888888888888,
        0.8888888888888888
      ],
      "partial_accuracy_mean": 0.9324324324324325,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.9324324324324325,
        0.9324324324324325
      ],
      "partial_balanced_accuracy_mean": 0.9066666666666667,
      "partial_balanced_accuracy_std": 0.0,
      "partial_balanced_accuracy_values": [
        0.9066666666666667,
        0.9066666666666667
      ],
      "partial_adj_balanced_accuracy_mean": 0.8133333333333335,
      "partial_adj_balanced_accuracy_std": 0.0,
      "partial_adj_balanced_accuracy_values": [
        0.8133333333333335,
        0.8133333333333335
      ]
    },
    {
      "step": 28,
      "num_instructions": 2,
      "md5_hashes": [
        "15fe8f77b5947d65bef41b24a988a5db",
        "2cb642b0d94328d19d4d8217a38c72f3"
      ],
      "combined_scores_mean": 0.824651482054682,
      "combined_scores_std": 0.0002545440496811713,
      "combined_scores_values": [
        0.8249060261043631,
        0.8243969380050008
      ],
      "word_counts_mean": 64.5,
      "word_counts_std": 0.5,
      "word_counts_values": [
        64,
        65
      ],
      "cancel_precision_mean": 0.9034608378870674,
      "cancel_precision_std": 0.014571948998178541,
      "cancel_precision_values": [
        0.8888888888888888,
        0.9180327868852459
      ],
      "cancel_recall_mean": 0.9333333333333333,
      "cancel_recall_std": 0.0,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9180944702009004,
      "cancel_f1_std": 0.00752536450984348,
      "cancel_f1_values": [
        0.9105691056910569,
        0.9256198347107438
      ],
      "cancel_accuracy_mean": 0.9519230769230769,
      "cancel_accuracy_std": 0.004807692307692346,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9567307692307693
      ],
      "cancel_balanced_accuracy_mean": 0.9463963963963964,
      "cancel_balanced_accuracy_std": 0.003378378378378344,
      "cancel_balanced_accuracy_values": [
        0.9430180180180181,
        0.9497747747747748
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8927927927927929,
      "cancel_adj_balanced_accuracy_std": 0.006756756756756688,
      "cancel_adj_balanced_accuracy_values": [
        0.8860360360360362,
        0.8995495495495496
      ],
      "partial_precision_mean": 0.9618421052631578,
      "partial_precision_std": 0.011842105263157932,
      "partial_precision_values": [
        0.95,
        0.9736842105263158
      ],
      "partial_recall_mean": 0.78125,
      "partial_recall_std": 0.01041666666666663,
      "partial_recall_values": [
        0.7916666666666666,
        0.7708333333333334
      ],
      "partial_f1_mean": 0.8620507399577166,
      "partial_f1_std": 0.0015856236786469524,
      "partial_f1_values": [
        0.8636363636363636,
        0.8604651162790697
      ],
      "partial_accuracy_mean": 0.918918918918919,
      "partial_accuracy_std": 0.0,
      "partial_accuracy_values": [
        0.918918918918919,
        0.918918918918919
      ],
      "partial_balanced_accuracy_mean": 0.8831249999999999,
      "partial_balanced_accuracy_std": 0.0027083333333333126,
      "partial_balanced_accuracy_values": [
        0.8858333333333333,
        0.8804166666666666
      ],
      "partial_adj_balanced_accuracy_mean": 0.7662499999999999,
      "partial_adj_balanced_accuracy_std": 0.005416666666666625,
      "partial_adj_balanced_accuracy_values": [
        0.7716666666666665,
        0.7608333333333333
      ]
    },
    {
      "step": 29,
      "num_instructions": 3,
      "md5_hashes": [
        "eab4b0fcf267e53fe61529f4542b3c4d",
        "d9f949905b010526a5dd541365b0bc62",
        "8b0ee0e18d9bcf45ca201ed7899181e9"
      ],
      "combined_scores_mean": 0.8612586066536224,
      "combined_scores_std": 0.0047507822841632375,
      "combined_scores_values": [
        0.8593193413374881,
        0.8677990862843238,
        0.8566573923390554
      ],
      "word_counts_mean": 66.33333333333333,
      "word_counts_std": 0.4714045207910317,
      "word_counts_values": [
        67,
        66,
        66
      ],
      "cancel_precision_mean": 0.8984468339307049,
      "cancel_precision_std": 0.006758487753276451,
      "cancel_precision_values": [
        0.8888888888888888,
        0.9032258064516129,
        0.9032258064516129
      ],
      "cancel_recall_mean": 0.9333333333333332,
      "cancel_recall_std": 1.1102230246251565e-16,
      "cancel_recall_values": [
        0.9333333333333333,
        0.9333333333333333,
        0.9333333333333333
      ],
      "cancel_f1_mean": 0.9155448931538496,
      "cancel_f1_std": 0.003518413056683726,
      "cancel_f1_values": [
        0.9105691056910569,
        0.9180327868852459,
        0.9180327868852459
      ],
      "cancel_accuracy_mean": 0.9503205128205128,
      "cancel_accuracy_std": 0.0022663678884184135,
      "cancel_accuracy_values": [
        0.9471153846153846,
        0.9519230769230769,
        0.9519230769230769
      ],
      "cancel_balanced_accuracy_mean": 0.9452702702702703,
      "cancel_balanced_accuracy_std": 0.0015925828405101998,
      "cancel_balanced_accuracy_values": [
        0.9430180180180181,
        0.9463963963963964,
        0.9463963963963964
      ],
      "cancel_adj_balanced_accuracy_mean": 0.8905405405405405,
      "cancel_adj_balanced_accuracy_std": 0.0031851656810203996,
      "cancel_adj_balanced_accuracy_values": [
        0.8860360360360362,
        0.8927927927927928,
        0.8927927927927928
      ],
      "partial_precision_mean": 0.9684295347936868,
      "partial_precision_std": 0.010567657138405935,
      "partial_precision_values": [
        0.9534883720930233,
        0.9761904761904762,
        0.975609756097561
      ],
      "partial_recall_mean": 0.8472222222222222,
      "partial_recall_std": 0.009820927516479791,
      "partial_recall_values": [
        0.8541666666666666,
        0.8541666666666666,
        0.8333333333333334
      ],
      "partial_f1_mean": 0.9036954722347982,
      "partial_f1_std": 0.00532156917629807,
      "partial_f1_values": [
        0.9010989010989011,
        0.9111111111111111,
        0.898876404494382
      ],
      "partial_accuracy_mean": 0.9414414414414414,
      "partial_accuracy_std": 0.003185165681020504,
      "partial_accuracy_values": [
        0.9391891891891891,
        0.9459459459459459,
        0.9391891891891891
      ],
      "partial_balanced_accuracy_mean": 0.9169444444444445,
      "partial_balanced_accuracy_std": 0.004253720230864905,
      "partial_balanced_accuracy_values": [
        0.9170833333333333,
        0.9220833333333334,
        0.9116666666666666
      ],
      "partial_adj_balanced_accuracy_mean": 0.8338888888888888,
      "partial_adj_balanced_accuracy_std": 0.008507440461729812,
      "partial_adj_balanced_accuracy_values": [
        0.8341666666666665,
        0.8441666666666667,
        0.8233333333333333
      ]
    }
  ],
  "config": {
    "train_data_path": "data/processed/logs/04222025-08182025/ground_truth/gpt-5-verified/verified_ground_truth_balance_train.json",
    "initial_prompt_file": "prompts/original/identify_partial.yaml",
    "initial_prompt_key": "initial_prompt_simple",
    "save_folder": "results/gpt-5-verified/meta_prompt_v1/exp_mode_random/threshold_0.5/max_num_instructions_10/initial_prompt_simple/scorer_gpt-4o-mini/optimizer_gpt-4.1/train_ratio_1.0/num_search_steps_30/num_gen_inst_4_num_exp_2_opt_temperature_1.0"
  }
}